<?xml version="1.0"?>
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="research-article" xml:lang="en">
      <front>
        <journal-meta>
          <journal-id journal-id-type="publisher-id">13321</journal-id>
          <journal-title-group>
            <journal-title>Journal of Cheminformatics</journal-title>
            <abbrev-journal-title abbrev-type="publisher">J Cheminform</abbrev-journal-title>
          </journal-title-group>
          <issn pub-type="epub">1758-2946</issn>
          <publisher>
            <publisher-name>Springer International Publishing</publisher-name>
            <publisher-loc>Cham</publisher-loc>
          </publisher>
        </journal-meta>
        <article-meta>
          <article-id pub-id-type="publisher-id">s13321-019-0368-1</article-id>
          <article-id pub-id-type="manuscript">368</article-id>
          <article-id pub-id-type="doi">10.1186/s13321-019-0368-1</article-id>
          <article-categories>
            <subj-group subj-group-type="heading">
              <subject>Research Article</subject>
            </subj-group>
            <subj-group subj-group-type="article-collection" specific-use="Regular">
              <subject>Proceedings of the 11th International Conference on Chemical Structures</subject>
            </subj-group>
          </article-categories>
          <title-group>
            <article-title xml:lang="en">Multi-channel PINN: investigating scalable and transferable neural networks for drug discovery</article-title>
          </title-group>
          <contrib-group>
            <contrib contrib-type="author" id="Au1">
              <name>
                <surname>Lee</surname>
                <given-names>Munhwan</given-names>
              </name>
              <address>
                <email>HIDDEN</email>
              </address>
              <xref ref-type="aff" rid="Aff1">1</xref>
            </contrib>
            <contrib contrib-type="author" id="Au2">
              <name>
                <surname>Kim</surname>
                <given-names>Hyeyeon</given-names>
              </name>
              <address>
                <email>HIDDEN</email>
              </address>
              <xref ref-type="aff" rid="Aff1">1</xref>
            </contrib>
            <contrib contrib-type="author" id="Au3">
              <name>
                <surname>Joe</surname>
                <given-names>Hyunwhan</given-names>
              </name>
              <address>
                <email>HIDDEN</email>
              </address>
              <xref ref-type="aff" rid="Aff1">1</xref>
            </contrib>
            <contrib contrib-type="author" corresp="yes" id="Au4">
              <name>
                <surname>Kim</surname>
                <given-names>Hong-Gee</given-names>
              </name>
              <address>
                <email>HIDDEN</email>
              </address>
              <xref ref-type="aff" rid="Aff1">1</xref>
              <xref ref-type="corresp" rid="IDs1332101903681_cor4">d</xref>
            </contrib>
            <aff id="Aff1">
              <label>1</label>
              <institution-wrap>
                <institution-id institution-id-type="ISNI">0000 0004 0470 5905</institution-id>
                <institution-id institution-id-type="GRID">grid.31501.36</institution-id>
                <institution content-type="org-division">Biomedical Knowledge Engineering Laboratory</institution>
                <institution content-type="org-name">Seoul National University</institution>
              </institution-wrap>
              <addr-line content-type="street">1 Gwanak-ro</addr-line>
              <addr-line content-type="city">Seoul</addr-line>
              <country country="KR">Republic of Korea</country>
            </aff>
          </contrib-group>
          <author-notes>
            <corresp id="IDs1332101903681_cor4">
              <label>d</label>
              <email>HIDDEN</email>
            </corresp>
          </author-notes>
          <pub-date date-type="pub" publication-format="electronic">
            <day>9</day>
            <month>7</month>
            <year>2019</year>
          </pub-date>
          <pub-date date-type="collection" publication-format="electronic">
            <month>12</month>
            <year>2019</year>
          </pub-date>
          <volume>11</volume>
          <issue seq="46">1</issue>
          <elocation-id>46</elocation-id>
          <history>
            <date date-type="registration">
              <day>2</day>
              <month>7</month>
              <year>2019</year>
            </date>
            <date date-type="received">
              <day>2</day>
              <month>10</month>
              <year>2018</year>
            </date>
            <date date-type="accepted">
              <day>2</day>
              <month>7</month>
              <year>2019</year>
            </date>
            <date date-type="online">
              <day>9</day>
              <month>7</month>
              <year>2019</year>
            </date>
          </history>
          <permissions>
            <copyright-statement content-type="compact">© The Author(s) 2019</copyright-statement>
            <copyright-year>2019</copyright-year>
            <copyright-holder>The Author(s)</copyright-holder>
            <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
              <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link xlink:href="http://creativecommons.org/publicdomain/zero/1.0/" ext-link-type="uri">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
            </license>
          </permissions>
          <abstract xml:lang="en" id="Abs1">
            <title>Abstract</title>
            <p id="Par1">Analysis of compound–protein interactions (CPIs) has become a crucial prerequisite for drug discovery and drug repositioning. In vitro experiments are commonly used in identifying CPIs, but it is not feasible to discover the molecular and proteomic space only through experimental approaches. Machine learning’s advances in predicting CPIs have made significant contributions to drug discovery. Deep neural networks (DNNs), which have recently been applied to predict CPIs, performed better than other shallow classifiers. However, such techniques commonly require a considerable volume of dense data for each training target. Although the number of publicly available CPI data has grown rapidly, public data is still sparse and has a large number of measurement errors. In this paper, we propose a novel method, <italic>Multi-channel PINN</italic>, to fully utilize sparse data in terms of representation learning. With representation learning, <italic>Multi-channel PINN</italic> can utilize three approaches of DNNs which are a classifier, a feature extractor, and an end-to-end learner. <italic>Multi-channel PINN</italic> can be fed with both low and high levels of representations and incorporates each of them by utilizing all approaches within a single model. To fully utilize sparse public data, we additionally explore the potential of transferring representations from training tasks to test tasks. As a proof of concept, <italic>Multi-channel PINN</italic> was evaluated on fifteen combinations of feature pairs to investigate how they affect the performance in terms of highest performance, initial performance, and convergence speed. The experimental results obtained indicate that the multi-channel models using protein features performed better than single-channel models or multi-channel models using compound features. Therefore, <italic>Multi-channel PINN</italic> can be advantageous when used with appropriate representations. Additionally, we pretrained models on a training task then finetuned them on a test task to figure out whether <italic>Multi-channel PINN</italic> can capture general representations for compounds and proteins. We found that there were significant differences in performance between pretrained models and non-pretrained models.</p>
          </abstract>
          <kwd-group xml:lang="en">
            <title>Keywords</title>
            <kwd>Deep neural networks</kwd>
            <kwd>Machine learning</kwd>
            <kwd>Compound–protein interaction</kwd>
            <kwd>Proteochemometrics</kwd>
            <kwd>Cheminformatics</kwd>
          </kwd-group>
          <funding-group>
            <award-group>
              <funding-source>
                <institution-wrap>
                  <institution>Institute for Information and communications Technology Promotion</institution>
                  <institution-id institution-id-type="doi" vocab="open-funder-registry">http://dx.doi.org/10.13039/501100010418</institution-id>
                </institution-wrap>
              </funding-source>
              <award-id award-type="FundRef grant">2017-0-00398</award-id>
              <principal-award-recipient>
                <name>
                  <surname>Kim</surname>
                  <given-names>Hong-Gee</given-names>
                </name>
              </principal-award-recipient>
            </award-group>
            <award-group>
              <funding-source>
                <institution-wrap>
                  <institution>Ministry of Science, ICT and Future Planning</institution>
                  <institution-id institution-id-type="doi" vocab="open-funder-registry">http://dx.doi.org/10.13039/501100003621</institution-id>
                </institution-wrap>
              </funding-source>
              <award-id award-type="FundRef grant">2017R1A2B2008729</award-id>
              <principal-award-recipient>
                <name>
                  <surname>Kim</surname>
                  <given-names>Hong-Gee</given-names>
                </name>
              </principal-award-recipient>
            </award-group>
          </funding-group>
          <custom-meta-group>
            <custom-meta>
              <meta-name>publisher-imprint-name</meta-name>
              <meta-value>Springer</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>volume-issue-count</meta-name>
              <meta-value>1</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-article-count</meta-name>
              <meta-value>0</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-toc-levels</meta-name>
              <meta-value>0</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-pricelist-year</meta-name>
              <meta-value>2019</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-copyright-holder</meta-name>
              <meta-value>The Author(s)</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-copyright-year</meta-name>
              <meta-value>2019</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-contains-esm</meta-name>
              <meta-value>Yes</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-numbering-style</meta-name>
              <meta-value>Unnumbered</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-registration-date-year</meta-name>
              <meta-value>2019</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-registration-date-month</meta-name>
              <meta-value>7</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-registration-date-day</meta-name>
              <meta-value>2</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-toc-levels</meta-name>
              <meta-value>0</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>toc-levels</meta-name>
              <meta-value>0</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>volume-type</meta-name>
              <meta-value>Regular</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-product</meta-name>
              <meta-value>ArchiveJournal</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>numbering-style</meta-name>
              <meta-value>Unnumbered</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-collection-editor</meta-name>
              <meta-value>Gerard van Westen, Markus Wagener</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-grants-type</meta-name>
              <meta-value>OpenChoice</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>metadata-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>abstract-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>bodypdf-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>bodyhtml-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>bibliography-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>esm-grant</meta-name>
              <meta-value>OpenAccess</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>online-first</meta-name>
              <meta-value>false</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>pdf-file-reference</meta-name>
              <meta-value>BodyRef/PDF/13321_2019_Article_368.pdf</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>pdf-type</meta-name>
              <meta-value>Typeset</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>target-type</meta-name>
              <meta-value>OnlinePDF</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>issue-type</meta-name>
              <meta-value>Regular</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>article-type</meta-name>
              <meta-value>OriginalPaper</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-primary</meta-name>
              <meta-value>Chemistry</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-secondary</meta-name>
              <meta-value>Computer Applications in Chemistry</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-secondary</meta-name>
              <meta-value>Documentation and Information in Chemistry</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-secondary</meta-name>
              <meta-value>Theoretical and Computational Chemistry</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-secondary</meta-name>
              <meta-value>Computational Biology/Bioinformatics</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>journal-subject-collection</meta-name>
              <meta-value>Chemistry and Materials Science</meta-value>
            </custom-meta>
            <custom-meta>
              <meta-name>open-access</meta-name>
              <meta-value>true</meta-value>
            </custom-meta>
          </custom-meta-group>
        </article-meta>
        <notes notes-type="ESMHint">
          <title>Electronic supplementary material</title>
          <p>The online version of this article (<ext-link xlink:href="10.1186/s13321-019-0368-1" ext-link-type="doi">https://doi.org/10.1186/s13321-019-0368-1</ext-link>) contains supplementary material, which is available to authorized users.</p>
        </notes>
      </front>
      <body>
        <sec id="Sec1">
          <title>Introduction</title>
          <p id="Par17">Analysis of compound–protein interactions (CPIs) has become an important prerequisite for both discovering novel drugs for known protein targets and repurposing new targets for current drugs [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref>]. Exploring both molecular and proteomic space is a highly challenging and cost-intensive procedure. Each space is enormous and heterogeneous, moreover, most of the CPIs space remains to be discovered. For example, there are roughly <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:msup><mml:mn>10</mml:mn><mml:mn>8</mml:mn></mml:msup></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{8}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq1.gif" /></alternatives></inline-formula> synthesized compounds potentially developed into novel drugs [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] but they are a small fraction of drug-like compounds, which the total is estimated on the order of between <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:msup><mml:mn>10</mml:mn><mml:mn>24</mml:mn></mml:msup></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{24}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq2.gif" /></alternatives></inline-formula> and <inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:msup><mml:mn>10</mml:mn><mml:mn>60</mml:mn></mml:msup></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{60}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq3.gif" /></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>]. As for the targets of the compounds, there are about 200,000 reviewed human protein records [<xref ref-type="bibr" rid="CR7">7</xref>]. In vitro experiments are commonly used in identifying CPIs, but it is not feasible to discover molecular and proteomic space only through experimental approaches. In silico models have emerged to aid traditional experiments by narrowing down the search space and prioritizing molecules with the highest potential [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR11">11</xref>].</p>
          <p id="Par18">Traditional in silico models can be grouped into two approaches, which are structure-based methods [<xref ref-type="bibr" rid="CR12">12</xref>–<xref ref-type="bibr" rid="CR14">14</xref>] and ligand-based methods [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR17">17</xref>]. In addition to the conventional approaches, proteochemometrics (PCM) methods have been proposed to predict CPIs by incorporating both ligand and target space within a single model [<xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR21">21</xref>]. First, structure-based methods yield reasonable prediction performance and visually interpretable results. Structure-based methods use three-dimensional (3D) simulation for molecular docking to discover CPIs. AutoDock [<xref ref-type="bibr" rid="CR22">22</xref>], Glide [<xref ref-type="bibr" rid="CR23">23</xref>], Fred [<xref ref-type="bibr" rid="CR24">24</xref>], and AtomNet [<xref ref-type="bibr" rid="CR25">25</xref>] are examples of docking tools. However, the methods have two major limitations: (1) intensive computational complexity and (2) the shortage of 3D structure data for compounds and proteins. Therefore, ligand-based and PCM methods are preferred in most cases.</p>
          <p id="Par19">Secondly, ligand-based methods depend on a basic assumption called the molecular similarity principle [<xref ref-type="bibr" rid="CR26">26</xref>]. The assumption is that similar compounds are used to interact with similar proteins, where Quantitative Structure–Activity Relationship (QSAR) model is one of the representative examples. With the advent of machine learning (ML) algorithms, ligand-based methods, such as Naïve Bayes (NB) [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR28">28</xref>], random forest (RF) [<xref ref-type="bibr" rid="CR29">29</xref>], support vector machines (SVM) [<xref ref-type="bibr" rid="CR30">30</xref>], deep neural networks (DNNs) [<xref ref-type="bibr" rid="CR31">31</xref>] and multi-task neural networks [<xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR33">33</xref>], have gained popularity. However, molecular activity alone is not sufficient to identify the bioactivity.</p>
          <p id="Par20">In contrast to ligand-based methods, PCM methods build a model using each compound and protein pair as the input data to fully utilize both proteomic and molecular space. Due to their pair-based modelling, PCM methods are able to predict the interactions between novel compounds and new proteins. PCM methods have recently demonstrated their performance in various tasks such as the identification of new drug combinations [<xref ref-type="bibr" rid="CR34">34</xref>], prediction of interactions between drug and target [<xref ref-type="bibr" rid="CR35">35</xref>], and CPIs prediction for G protein coupled receptor (GPCR) and protein kinase targets [<xref ref-type="bibr" rid="CR36">36</xref>]. In addition, PCM has the potential to utilize information from various multispecies into a single model [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR37">37</xref>]. Therefore, PCM methods have drawn attention in discovering CPI space [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
          <p id="Par21">DNN algorithms have recently been applied to predict CPI pairs and performed better than other shallow classifiers such as RF, NB and SVM [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. In addition to using basic DNNs called feedforward neural networks (FFNN), a previous study [<xref ref-type="bibr" rid="CR40">40</xref>] has proposed pairwise input neural networks (PINN). As a variation of a FFNN, a PINN consists of two separated layers and one concatenated layer. Each separated layer is fed with a different feature as the input (i.e. compound and protein) and then each layer is concatenated before classifying the classes. Before the concatenated layers, each separated layer is independently composed without connection from other layers. This architecture allows PINN to reduce the total number of parameters in the networks by about 50% compared to the conventional FFNN without degradation in performance (see Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S1). The architecture is also suitable for PCM methods, which utilize both compound and protein features. However, the majority of DNNs commonly require a considerable volume of data for each training target. Although the number of public available CPI pairs has grown rapidly, it is still not sufficient to model CPI space [<xref ref-type="bibr" rid="CR41">41</xref>].</p>
          <p id="Par22">Moreover, as a recent study by Lenselink et al. [<xref ref-type="bibr" rid="CR38">38</xref>] pointed out, public data can have a large number of errors due to the use of different scientific protocols. The authors presented a high-quality benchmark dataset and compared the performance between various combinations of descriptors, methods (PCM and QSAR), machine learning algorithms, and validation partitioning. The study found that PCM models generally exceed QSAR models under the same conditions. PCM-based DNNs algorithms outperformed the other models on both evaluation sets (temporal validation and random validation).</p>
          <p id="Par23">To complete the modelling of CPI space [<xref ref-type="bibr" rid="CR20">20</xref>], there is still room for improvement for PCM-based DNNs in terms of representation learning. DNNs can be utilized with three approaches including a classifier, a feature extractor, and an end-to-end learner. As a classifier, DNN algorithms in drug discovery are generally fed with manually crafted features and predict the bioactivity. DNNs can also be used as a feature extractor for compound and protein descriptors [<xref ref-type="bibr" rid="CR42">42</xref>, <xref ref-type="bibr" rid="CR43">43</xref>] to fully utilize the information in large-scale dataset such as ZINC for compounds [<xref ref-type="bibr" rid="CR44">44</xref>] and UniProt for proteins [<xref ref-type="bibr" rid="CR45">45</xref>]. As an end-to-end learner, DNNs can learn representations from raw data such as SMILES string of compounds and amino acid sequence of proteins. End-to-end learning manages the whole learning process from feature extraction to classification in a single model.</p>
          <p id="Par24">In this paper, we propose a novel multi-channel PCM-based DNN called <italic>Multi-channel PINN</italic> (<italic>MCPINN</italic>). In order to make full use of sparse data, <italic>MCPINN</italic> utilizes three approaches of DNNs which are a classifier, a feature extractor, and an end-to-end learner. This model can be fed with both low and high levels of representations and can incorporate each of them into a single model (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). With PINN architecture, this model takes both compounds and proteins into the input layer. It takes SMILES strings, ECFPs and vectors embedded by Mol2vec [<xref ref-type="bibr" rid="CR42">42</xref>] for compounds and amino acid sequences and vectors embedded by ProtVec [<xref ref-type="bibr" rid="CR43">43</xref>] for proteins. By incorporating the three approaches of DNNs, <italic>MCPINN</italic> can learn multiple representations to model the CPI data space. In addition to improving the model, we explore the potential ability of <italic>MCPINN</italic> to transfer the generalized representations from a high quality and well balanced training dataset to a strongly imbalanced test dataset.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>Schematic representations of <italic>Multi-channel PINN</italic> (<italic>MCPINN</italic>). <italic>MCPINN</italic> utilizes the three approaches of DNN in terms of a classifier, a feature extractor, and an end-to-end learner. <italic>MCPINN</italic> can incorporate both low and high level representations in a single model</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig1_HTML.png" id="MO1" /></fig></p>
          <p id="Par25">As a proof of concept, we evaluated <italic>MCPINN</italic> on a standardized benchmark dataset [<xref ref-type="bibr" rid="CR38">38</xref>] obtained from ChEMBL, using MCC and ROC as evaluation metrics. To investigate the effect of each feature, <italic>MCPINN</italic> was evaluated with six combinations of single-channel feature pairs. <italic>MCPINN</italic> was also evaluated with nine combinations of multi-channel feature pairs to explore the synergy effects of low and high levels of representations. The models were investigated in terms of not only highest performance but also initial performance and convergence speed. To test whether <italic>MCPINN</italic> can transfer general representations of compounds and proteins to a new task, we pretrained models on a training task, which is the benchmark dataset used above, and then finetuned the pretrained models on a test task Tox21 [<xref ref-type="bibr" rid="CR46">46</xref>]. The transferability of <italic>MCPINN</italic> was evaluated in terms of initial performance, speed of convergence, and highest performance using two metrics for validation MCC and PRC. Therefore, this study contributes to “the complete modelling of CPI space” [<xref ref-type="bibr" rid="CR20">20</xref>] by full use of representation ability of DNNs as a classifier, a feature extractor, and an end-to-end learner and additionally by transferring the generalized representations from training tasks to test task.</p>
        </sec>
        <sec id="Sec2">
          <title>Results and discussion</title>
          <sec id="Sec3">
            <title>Investigating the representation learning ability</title>
            <p id="Par26">The first part of this study focuses on the representation learning ability of <italic>MCPINN</italic>. To figure out the contribution of each feature on the predictive performance of the model, <italic>MCPINN</italic> was evaluated with fifteen combinations of feature pairs, which contained six pairs from single-channel features and nine pairs from multi-channel features. There are three features for compounds: SMILES, ECFP, and Mol2vec, where SMILES is a low-level representation. The performance based on the feature concatenated ECFP and Mol2vec was evaluated but omitted because the concatenated feature models did not provide improvement in performance compared to the Mol2vec or ECFP models separately (as can be seen in Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S2). Two features are used for proteins: ProtVec and the amino acid sequence which is a low-level representation. For low-level representations (SMILES and amino acid sequence) Dilated CNN is applied as an end-to-end learner. Recurrent Neural Network models were also trained but omitted due to their poor performance, which can be seen in Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Figures S1 and S2.</p>
            <p id="Par27">There are fifteen models based on the combinations of feature pairs and are listed in Table <xref rid="Tab1" ref-type="table">1</xref> with shortened names. The models were evaluated on a benchmark dataset [<xref ref-type="bibr" rid="CR38">38</xref>] using two metrics for validation the Matthew Correlation Coefficient (MCC) and Receiver Operating Characteristic Area Under the Curve (ROC).<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>The shortened names for combinations of features for <italic>SCPINN</italic> and <italic>MCPINN</italic></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Model name</p></th><th align="left"><p>Channel type</p></th><th align="left"><p>Compound feature</p></th><th align="left"><p>Protein feature</p></th></tr></thead><tbody><tr><td align="left"><p><inline-formula id="IEq4"><alternatives><mml:math id="IEq4_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq4.gif" /></alternatives></inline-formula></p></td><td align="left" rowspan="6"><p>Single-channel</p></td><td align="left"><p>SMILES</p></td><td align="left"><p>AA sequence</p></td></tr><tr><td align="left"><p><inline-formula id="IEq5"><alternatives><mml:math id="IEq5_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq5.gif" /></alternatives></inline-formula></p></td><td align="left"><p>SMILES</p></td><td align="left"><p>ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq6"><alternatives><mml:math id="IEq6_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_3$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq6.gif" /></alternatives></inline-formula></p></td><td align="left"><p>Mol2vec</p></td><td align="left"><p>AA sequence</p></td></tr><tr><td align="left"><p><inline-formula id="IEq7"><alternatives><mml:math id="IEq7_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq7.gif" /></alternatives></inline-formula></p></td><td align="left"><p>Mol2vec</p></td><td align="left"><p>ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq8"><alternatives><mml:math id="IEq8_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_5$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq8.gif" /></alternatives></inline-formula></p></td><td align="left"><p>ECFP</p></td><td align="left"><p>AA sequence</p></td></tr><tr><td align="left"><p><inline-formula id="IEq9"><alternatives><mml:math id="IEq9_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_6$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq9.gif" /></alternatives></inline-formula></p></td><td align="left"><p>ECFP</p></td><td align="left"><p>ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq10"><alternatives><mml:math id="IEq10_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq10.gif" /></alternatives></inline-formula></p></td><td align="left" rowspan="3"><p>Multi-channel for protein</p></td><td align="left"><p>SMILES</p></td><td align="left"><p>AA sequence and ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq11"><alternatives><mml:math id="IEq11_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq11.gif" /></alternatives></inline-formula></p></td><td align="left"><p>Mol2vec</p></td><td align="left"><p>AA sequence and ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq12"><alternatives><mml:math id="IEq12_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_3$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq12.gif" /></alternatives></inline-formula></p></td><td align="left"><p>ECFP</p></td><td align="left"><p>AA sequence and ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq13"><alternatives><mml:math id="IEq13_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq13.gif" /></alternatives></inline-formula></p></td><td align="left" rowspan="4"><p>Multi-channel for compound</p></td><td align="left"><p>SMILES and Mol2vec</p></td><td align="left"><p>AA sequence</p></td></tr><tr><td align="left"><p><inline-formula id="IEq14"><alternatives><mml:math id="IEq14_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_5$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq14.gif" /></alternatives></inline-formula></p></td><td align="left"><p>SMILES and Mol2vec</p></td><td align="left"><p>ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq15"><alternatives><mml:math id="IEq15_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_6$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq15.gif" /></alternatives></inline-formula></p></td><td align="left"><p>SMILES and ECFP</p></td><td align="left"><p>AA sequence</p></td></tr><tr><td align="left"><p><inline-formula id="IEq16"><alternatives><mml:math id="IEq16_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>7</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_7$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq16.gif" /></alternatives></inline-formula></p></td><td align="left"><p>SMILES and ECFP</p></td><td align="left"><p>ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq17"><alternatives><mml:math id="IEq17_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>8</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_8$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq17.gif" /></alternatives></inline-formula></p></td><td align="left" rowspan="2"><p>Multi-channel for both features</p></td><td align="left"><p>SMILES and Mol2vec</p></td><td align="left"><p>AA sequence and ProtVec</p></td></tr><tr><td align="left"><p><inline-formula id="IEq18"><alternatives><mml:math id="IEq18_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq18.gif" /></alternatives></inline-formula></p></td><td align="left"><p>SMILES and ECFP</p></td><td align="left"><p>AA sequence and ProtVec</p></td></tr></tbody></table></table-wrap></p>
            <sec id="Sec4">
              <title>Comparison between single-channel models</title>
              <p id="Par28">Above all, to investigate the effect of each feature on the predictive performance of the model, the six feature pairs are explored with Single-channel PINN (<italic>SCPINN</italic>). <italic>SCPINN</italic> is a basic model that is fed with only one feature for each protein and compound respectively as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. The prediction performance of each model is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The average performance of <italic>SCPINN</italic> models was an MCC of 0.636 ± 0.03 and a ROC of 0.892 ± 0.02. Overall the differences in performances between the metrics scores were similar to each other. It is observed that the biggest difference in performance between the <italic>SCPINN</italic> models was the use of a high-level representation (ECFP and Mol2vec) in the chemical feature instead of a low-level representation (SMILES). For example, the average performance of the models using ECFP and Mol2vec for compounds was an MCC of 0.66 ± 0.008 and a ROC of 0.90 ± 0.004, while the average performance of the models using SMILES was an MCC of 0.60 ± 0.014 and a ROC of 0.87 ± 0.007.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Comparison of predictive performance between <italic>SCPINN</italic>. On the left y-axis the MCC is shown, while on the right y-axis the ROC score is shown and error bars indicate SEM. Mean MCC is 0.636 (± 0.03) and mean ROC is 0.892 (± 0.02)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig2_HTML.png" id="MO2" /></fig></p>
              <p id="Par29">On the other hand, the models using ProtVec did not outperform the models using amino acid sequence with Dilated CNN for the overall models, regardless of the types of chemical features used. The average MCC of models using amino acid sequence was 0.646 (± 0.023) and mean ROC was 0.896 (± 0.011), while the average MCC of models using ProtVec was 0.627 (± 0.029) and the mean ROC was 0.887 (± 0.015).</p>
              <p id="Par30">This difference in performance seems to be based on whether or not the feature extraction method is able to capture the order of the amino acid sequences in the feature vector, in addition to the content itself. The Dilated CNN model can featurize the entire sequence of a protein in terms of the order and content, whereas ProtVec has a limitation in that it does not reflect the order of the sequence in the feature vector. ProtVec divides the sequence into N-grams to make the word units, performs individual embedding on each N-gram word, and then sums up all the embedding vectors regardless of the orders. Therefore, different proteins could have the same embedding vectors with ProtVec, provided the same N-grams are used.</p>
              <p id="Par31">Secondly, there is room to improve operations in Mol2vec and ProtVec to prevent incorrect representations of embedded compounds and proteins. In Mol2vec and ProtVec, the sum operation reconstructs embedded word vectors (i.e. Morgan substructure or N-gram amino acid sequence) into a sentence vector (i.e. compound or protein). Since the number of sum operations is dependent on the number of words in the sentence, applying these operations can significantly alter the embedded value of the sentence, regardless of the actual meaning of the sentence. To prevent information distortion, the sum operation in Mol2vec and ProtVec should be improved. Therefore, in the next section, we first refine the sum operation.</p>
            </sec>
            <sec id="Sec5">
              <title>Improving Mol2vec and ProtVec</title>
              <p id="Par32">To refine the sum operation in Mol2vec and ProtVec, we tested two types of weighted average operations, which are arithmetic mean and Term Frequency Inverse Document Frequency (TF-IDF) [<xref ref-type="bibr" rid="CR47">47</xref>]. The former sets the weight of each word according to the length of the sentence while the latter sets the weight of each word by TF-IDF (see "<xref rid="Sec11" ref-type="sec">Methods and materials</xref>" section). Table <xref rid="Tab2" ref-type="table">2</xref> shows the predictive performance of nine combinations of feature pairs using the original methods and the proposed methods for both Mol2vec and ProtVec. The proposed methods performed better than original methods with the exception of the arithmetic mean method on proteins. The best method for Mol2vec is the arithmetic mean method having an average MCC of 0.659 ± 0.013 and an average ROC 0.906 ± 0.004, compared to TF-IDF weighted average method (MCC of 0.657 ± 0.013 and ROC of 0.903 ± 0.002), and the original methods (MCC of 0.649 ± 0.014 and ROC of 0.903 ± 0.006). For ProtVec, the TF-IDF weighted average method outperformed the other models with an average MCC of 0.673 ± 0.04 and an average ROC of 0.909 ± 0.003. Among all of the usage of Mol2vec and ProtVec, the best performing feature pair is arithmetic mean method for the former and TF-IDF weighted average method for the latter, where the usage of the pair showed an MCC of 0.678 ± 0.002 and a ROC of 0.912 ± 0.002.<table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>Comparison of <inline-formula id="IEq19"><alternatives><mml:math id="IEq19_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq19.gif" /></alternatives></inline-formula>’s performance obtained by different methods in Mol2vec and ProtVec</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Mol2vec</p></th><th align="left"><p>ProtVec</p></th><th align="left"><p>MCC</p></th><th align="left"><p>ROC</p></th></tr></thead><tbody><tr><td align="left"><p>Mean</p></td><td align="left"><p>Sum</p></td><td char="(" align="char"><p>0.652 (± 0.004)</p></td><td char="(" align="char"><p>0.905 (± 0.002)</p></td></tr><tr><td align="left"><p>Mean</p></td><td align="left"><p>Mean</p></td><td char="(" align="char"><p>0.648 (± 0.003)</p></td><td char="(" align="char"><p>0.902 (± 0.003)</p></td></tr><tr><td align="left"><p>Mean</p></td><td align="left"><p>TF-IDF</p></td><td char="(" align="char"><p>0.678 (± 0.002)</p></td><td char="(" align="char"><p>0.912 (± 0.002)</p></td></tr><tr><td align="left"><p>TF-IDF</p></td><td align="left"><p>Sum</p></td><td char="(" align="char"><p>0.651 (± 0.003)</p></td><td char="(" align="char"><p>0.904 (± 0.003)</p></td></tr><tr><td align="left"><p>TF-IDF</p></td><td align="left"><p>Mean</p></td><td char="(" align="char"><p>0.644 (± 0.002)</p></td><td char="(" align="char"><p>0.901 (± 0.002)</p></td></tr><tr><td align="left"><p>TF-IDF</p></td><td align="left"><p>TF-IDF</p></td><td char="(" align="char"><p>0.674 (± 0.004)</p></td><td char="(" align="char"><p>0.905 (± 0.002)</p></td></tr><tr><td align="left"><p>Sum</p></td><td align="left"><p>Sum</p></td><td char="(" align="char"><p>0.642 (± 0.005)</p></td><td char="(" align="char"><p>0.900 (± 0.003)</p></td></tr><tr><td align="left"><p>Sum</p></td><td align="left"><p>Mean</p></td><td char="(" align="char"><p>0.636 (± 0.003)</p></td><td char="(" align="char"><p>0.898 (± 0.003)</p></td></tr><tr><td align="left"><p>Sum</p></td><td align="left"><p>TF-IDF</p></td><td char="(" align="char"><p>0.668 (± 0.002)</p></td><td char="(" align="char"><p>0.911 (± 0.002)</p></td></tr></tbody></table></table-wrap></p>
              <p id="Par33">It is observed that these improved methods can more accurately capture the contents of each compound and protein. The sentences (i.e. compounds and proteins) within each document (i.e. bioactivity dataset) have specific contexts and characteristics, which the entire corpus set (i.e. ZINC and UniProt) cannot represent. In particular, TF-IDF assigns a weight to each word in a sentence, so that TF-IDF weighted average method is able to more finely capture the characteristics and contexts inherent in the document.</p>
              <p id="Par34">In the case of Mol2vec, the TF-IDF weighted average method has a slightly lower performance than the arithmetic mean method. It seems that the TF-IDF weights from a specific document can be used to bias the information toward the document and reduce the generalization performance. In summary, all words were first embedded within the whole corpus, and then sentences were represented by weighting each word through a document. As a result, <inline-formula id="IEq20"><alternatives><mml:math id="IEq20_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq20.gif" /></alternatives></inline-formula> performed better than original one, where MCC increased to 0.678 from 0.642 and ROC increased to 0.912 from 0.900.</p>
            </sec>
            <sec id="Sec6">
              <title>Comparing the performance of multi-channel models</title>
              <p id="Par35">To figure out the synergy effects of a combination of both low and high level representation, the nine <italic>MCPINN</italic> models based on multi-channel feature pairs are evaluated as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. In order to improve the readability of this paper, the three multi-channel features are abbreviated as follows: ProtVec with amino acid sequences is ProtVec<inline-formula id="IEq21"><alternatives><mml:math id="IEq21_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq21.gif" /></alternatives></inline-formula>, Mol2vec with SMILES strings is Mol2vec<inline-formula id="IEq22"><alternatives><mml:math id="IEq22_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq22.gif" /></alternatives></inline-formula>, ECFP with SMILES strings is ECFP<inline-formula id="IEq23"><alternatives><mml:math id="IEq23_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq23.gif" /></alternatives></inline-formula>. It is observed that the effect of multi-channel was different between proteins and compounds, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. In the case of protein features, it was observed that the usage of ProtVec<inline-formula id="IEq24"><alternatives><mml:math id="IEq24_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq24_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq24.gif" /></alternatives></inline-formula> performed better than the others (average MCC of 0.658 ± 0.03 vs. 0.649 ± 0.03 and average ROC of 0.902 ± 0.02 vs. 0.897 ± 0.02). End to end learning channel with Dilated CNN seems to mainly represent the order (sentence level) of the amino acid sequence, while ProtVec channel represents the importance (word level) of each amino acid sequence in the protein. This suggests that the proposed multi-channel architecture can utilize both channels to capture features from both sentence and word perspectives for proteins.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Comparison of predictive performance between <italic>MCPINN</italic>. On the left y-axis the MCC is shown, while on the right y-axis the ROC score is shown and error bars indicate SEM. Mean MCC is 0.658 (± 0.02) and mean ROC is 0.902 (± 0.009)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig3_HTML.png" id="MO3" /></fig></p>
              <p id="Par36">Contrary to expectations, multi-channel models for compounds demonstrated very different results between the usage of ECFP<inline-formula id="IEq25"><alternatives><mml:math id="IEq25_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq25_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq25.gif" /></alternatives></inline-formula> and Mol2vec<inline-formula id="IEq26"><alternatives><mml:math id="IEq26_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq26_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq26.gif" /></alternatives></inline-formula>. For example, the usage of ECFP<inline-formula id="IEq27"><alternatives><mml:math id="IEq27_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq27_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq27.gif" /></alternatives></inline-formula> performed only slightly better than the usage of ECFP (MCC of 0.670 ± 0.004 vs. 0.669 ± 0.005 and ROC of 0.907 ± 0.002 and 0.906 ± 0.003). Moreover, the models using Mol2vec<inline-formula id="IEq28"><alternatives><mml:math id="IEq28_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq28_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq28.gif" /></alternatives></inline-formula> performed worse than the models using Mol2vec, where the average MCC dropped to 0.65 (± 0.002) from 0.68 (± 0.006) and the average ROC dropped to 0.89 (± 0.001) from 0.91 (± 0.003). In addition, the usage of Mol2vec<inline-formula id="IEq29"><alternatives><mml:math id="IEq29_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq29_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq29.gif" /></alternatives></inline-formula> also resulted in lower training performance than ECFP<inline-formula id="IEq30"><alternatives><mml:math id="IEq30_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq30_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq30.gif" /></alternatives></inline-formula>, where the average training performance was an MCC of 0.97 ± 0.006 for the models using ECFP<inline-formula id="IEq31"><alternatives><mml:math id="IEq31_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq31_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq31.gif" /></alternatives></inline-formula> and an MCC of 0.95 ± 0.007 for the models using Mol2vec<inline-formula id="IEq32"><alternatives><mml:math id="IEq32_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq32_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq32.gif" /></alternatives></inline-formula>. Therefore, a careful selection of representations is required to achieve better performance.</p>
              <p id="Par37">These results suggest that the richness of the features of compounds highly depend on the base representations. For example, compounds are represented in the form of a two-dimensional graph as the raw data for ECFP and Mol2vec, where they divide the graph into substructures and define each part to extract compound features. In contrast, Dilated CNN extracts features from an one-dimensional SMILES strings and it seems to capture less generalized representations from the strings compared to the representations from ECFP and Mol2vec. In this study, sequence data was used for the multi-channel architecture but there are a variety of other data types that can be embedded and used for a new channel. Therefore, the more embedding methods applied to a variety of data types such as graphs [<xref ref-type="bibr" rid="CR48">48</xref>], heterogeneous networks [<xref ref-type="bibr" rid="CR49">49</xref>], and nodes [<xref ref-type="bibr" rid="CR50">50</xref>], the more biological and molecular information (i.e. pathway and drug–drug interactions) can be fully utilized for drug discovery, poly-pharmacology, side-effect prediction, and drug resistance.</p>
            </sec>
            <sec id="Sec7">
              <title>Ranking the features and models</title>
              <p id="Par39">We compared and ranked fifteen models including the six <italic>SCPINN</italic> models and the nine <italic>MCPINN</italic> models introduced above. To compare between the models, we calculated two z-scores for each model and metric (MCC and ROC) and averaged them as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref> and Table <xref rid="Tab3" ref-type="table">3</xref>. To verify the validity of the difference between the z-scores, the following statistical tests were performed: the paired Student’s <italic>t</italic> Test and the <italic>F</italic> Test.<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Comparison of the mean z-scores obtained by the different models and error bars indicate SEM. Bars are colored by compound features, which are blue bars for Mol2vec, green bars for ECFP<inline-formula id="IEq66"><alternatives><mml:math id="IEq66_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq66_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq66.gif" /></alternatives></inline-formula>, yellow bars for ECFP, purple bars for Mol2vec<inline-formula id="IEq67"><alternatives><mml:math id="IEq67_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq67_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq67.gif" /></alternatives></inline-formula>, and grey bars for SMILES. The bars highlighted with red border indicate the usage of ProtVec<inline-formula id="IEq68"><alternatives><mml:math id="IEq68_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq68_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq68.gif" /></alternatives></inline-formula>, which demonstrates better performance than other protein features</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig4_HTML.png" id="MO4" /></fig><table-wrap id="Tab3"><label>Table 3</label><caption xml:lang="en"><p>Comparison of performance between models expressed as z-scores per experiment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Model</p></th><th align="left"><p>MCC</p></th><th align="left"><p>ROC</p></th><th align="left"><p>Average</p></th><th align="left"><p>SEM</p></th></tr></thead><tbody><tr><td align="left"><p>MC<inline-formula id="IEq33"><alternatives><mml:math id="IEq33_Math"><mml:msub><mml:mrow /><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="IEq33_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{2}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq33.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>1.22</p></td><td char="." align="char"><p>1.22</p></td><td char="." align="char"><p>1.22</p></td><td char="." align="char"><p>0.001</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq34"><alternatives><mml:math id="IEq34_Math"><mml:msub><mml:mrow /><mml:mn>4</mml:mn></mml:msub></mml:math><tex-math id="IEq34_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{4}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq34.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.91</p></td><td char="." align="char"><p>0.95</p></td><td char="." align="char"><p>0.93</p></td><td char="." align="char"><p>0.020</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq35"><alternatives><mml:math id="IEq35_Math"><mml:msub><mml:mrow /><mml:mn>9</mml:mn></mml:msub></mml:math><tex-math id="IEq35_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{9}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq35.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.77</p></td><td char="." align="char"><p>0.73</p></td><td char="." align="char"><p>0.75</p></td><td char="." align="char"><p>0.017</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq36"><alternatives><mml:math id="IEq36_Math"><mml:msub><mml:mrow /><mml:mn>3</mml:mn></mml:msub></mml:math><tex-math id="IEq36_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{3}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq36.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.72</p></td><td char="." align="char"><p>0.75</p></td><td char="." align="char"><p>0.74</p></td><td char="." align="char"><p>0.018</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq37"><alternatives><mml:math id="IEq37_Math"><mml:msub><mml:mrow /><mml:mn>3</mml:mn></mml:msub></mml:math><tex-math id="IEq37_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{3}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq37.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.69</p></td><td char="." align="char"><p>0.65</p></td><td char="." align="char"><p>0.67</p></td><td char="." align="char"><p>0.020</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq38"><alternatives><mml:math id="IEq38_Math"><mml:msub><mml:mrow /><mml:mn>7</mml:mn></mml:msub></mml:math><tex-math id="IEq38_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{7}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq38.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.64</p></td><td char="." align="char"><p>0.58</p></td><td char="." align="char"><p>0.61</p></td><td char="." align="char"><p>0.027</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq39"><alternatives><mml:math id="IEq39_Math"><mml:msub><mml:mrow /><mml:mn>6</mml:mn></mml:msub></mml:math><tex-math id="IEq39_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{6}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq39.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.64</p></td><td char="." align="char"><p>0.58</p></td><td char="." align="char"><p>0.61</p></td><td char="." align="char"><p>0.030</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq40"><alternatives><mml:math id="IEq40_Math"><mml:msub><mml:mrow /><mml:mn>6</mml:mn></mml:msub></mml:math><tex-math id="IEq40_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{6}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq40.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.36</p></td><td char="." align="char"><p>0.32</p></td><td char="." align="char"><p>0.34</p></td><td char="." align="char"><p>0.027</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq41"><alternatives><mml:math id="IEq41_Math"><mml:msub><mml:mrow /><mml:mn>5</mml:mn></mml:msub></mml:math><tex-math id="IEq41_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{5}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq41.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>0.30</p></td><td char="." align="char"><p>0.20</p></td><td char="." align="char"><p>0.25</p></td><td char="." align="char"><p>0.050</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq42"><alternatives><mml:math id="IEq42_Math"><mml:msub><mml:mrow /><mml:mn>8</mml:mn></mml:msub></mml:math><tex-math id="IEq42_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{8}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq42.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 0.18</p></td><td char="." align="char"><p>− 0.04</p></td><td char="." align="char"><p>− 0.11</p></td><td char="." align="char"><p>0.069</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq46"><alternatives><mml:math id="IEq46_Math"><mml:msub><mml:mrow /><mml:mn>5</mml:mn></mml:msub></mml:math><tex-math id="IEq46_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{5}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq46.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 0.34</p></td><td char="." align="char"><p>− 0.26</p></td><td char="." align="char"><p>− 0.30</p></td><td char="." align="char"><p>0.038</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq50"><alternatives><mml:math id="IEq50_Math"><mml:msub><mml:mrow /><mml:mn>4</mml:mn></mml:msub></mml:math><tex-math id="IEq50_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{4}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq50.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 0.42</p></td><td char="." align="char"><p>− 0.27</p></td><td char="." align="char"><p>− 0.34</p></td><td char="." align="char"><p>0.074</p></td></tr><tr><td align="left"><p>MC<inline-formula id="IEq54"><alternatives><mml:math id="IEq54_Math"><mml:msub><mml:mrow /><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="IEq54_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq54.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 1.50</p></td><td char="." align="char"><p>− 1.55</p></td><td char="." align="char"><p>− 1.53</p></td><td char="." align="char"><p>0.027</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq58"><alternatives><mml:math id="IEq58_Math"><mml:msub><mml:mrow /><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="IEq58_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq58.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 1.58</p></td><td char="." align="char"><p>− 1.63</p></td><td char="." align="char"><p>− 1.60</p></td><td char="." align="char"><p>0.027</p></td></tr><tr><td align="left"><p>SC<inline-formula id="IEq62"><alternatives><mml:math id="IEq62_Math"><mml:msub><mml:mrow /><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="IEq62_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{2}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq62.gif" /></alternatives></inline-formula></p></td><td char="." align="char"><p>− 2.24</p></td><td char="." align="char"><p>− 2.25</p></td><td char="." align="char"><p>− 2.24</p></td><td char="." align="char"><p>0.004</p></td></tr></tbody></table></table-wrap></p>
              <p id="Par40">Among the chemical features, the usage of Mol2Vec showed the best performance with an average z-score of <inline-formula id="IEq69"><alternatives><mml:math id="IEq69_Math"><mml:mrow><mml:mn>0.94</mml:mn><mml:mo>±</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math><tex-math id="IEq69_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.94 \pm 0.01$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq69.gif" /></alternatives></inline-formula>, compared to ECFP<inline-formula id="IEq70"><alternatives><mml:math id="IEq70_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq70_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq70.gif" /></alternatives></inline-formula> (<inline-formula id="IEq71"><alternatives><mml:math id="IEq71_Math"><mml:mrow><mml:mn>0.57</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math><tex-math id="IEq71_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.57 \pm 0.02$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq71.gif" /></alternatives></inline-formula>), ECFP (<inline-formula id="IEq72"><alternatives><mml:math id="IEq72_Math"><mml:mrow><mml:mn>0.53</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math><tex-math id="IEq72_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.53 \pm 0.02$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq72.gif" /></alternatives></inline-formula>), Mol2vec<inline-formula id="IEq73"><alternatives><mml:math id="IEq73_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq73_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq73.gif" /></alternatives></inline-formula> (<inline-formula id="IEq74"><alternatives><mml:math id="IEq74_Math"><mml:mrow><mml:mo>-</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.25</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math><tex-math id="IEq74_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-\,0.25 \pm 0.06$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq74.gif" /></alternatives></inline-formula>), and SMILES (<inline-formula id="IEq75"><alternatives><mml:math id="IEq75_Math"><mml:mrow><mml:mo>-</mml:mo><mml:mspace width="0.166667em" /><mml:mn>1.79</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math><tex-math id="IEq75_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-\,1.79 \pm 0.02$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq75.gif" /></alternatives></inline-formula>). For the Student’s <italic>t</italic> test, the usage of Mol2vec and SMILES are shown to significantly differ from all other features with a <italic>p</italic> value <inline-formula id="IEq76"><alternatives><mml:math id="IEq76_Math"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math><tex-math id="IEq76_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt;0.05$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq76.gif" /></alternatives></inline-formula>. Likewise, the usage of ECFP<inline-formula id="IEq77"><alternatives><mml:math id="IEq77_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq77_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq77.gif" /></alternatives></inline-formula> and ECFP differs significantly from all features with a <italic>p</italic> value <inline-formula id="IEq78"><alternatives><mml:math id="IEq78_Math"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math><tex-math id="IEq78_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt; 0.05$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq78.gif" /></alternatives></inline-formula> with the exception of the usage of Mol2vec<inline-formula id="IEq79"><alternatives><mml:math id="IEq79_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq79_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq79.gif" /></alternatives></inline-formula>, where the <italic>p</italic> value is 0.06 and 0.07 respectively (Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S3). For the <italic>F</italic> Test, the differences in variances are also noticeable from all features with a <italic>p</italic> value &lt; 0.05, with the exception of ECFP and ECFP<inline-formula id="IEq80"><alternatives><mml:math id="IEq80_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq80_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq80.gif" /></alternatives></inline-formula>, where the <italic>p</italic> value is 0.38 for each other (Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S4). Therefore, Mol2vec and Mol2vec<inline-formula id="IEq81"><alternatives><mml:math id="IEq81_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq81_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq81.gif" /></alternatives></inline-formula> showed significant differences in performance of both mean and variance, while ECFP and ECFP<inline-formula id="IEq82"><alternatives><mml:math id="IEq82_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq82_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq82.gif" /></alternatives></inline-formula> showed significant differences in mean performance.</p>
              <p id="Par41">Among the protein features, the usage of ProtVec<inline-formula id="IEq83"><alternatives><mml:math id="IEq83_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq83_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq83.gif" /></alternatives></inline-formula> outperformed the other features with an average z-scores of 0.21 (<inline-formula id="IEq84"><alternatives><mml:math id="IEq84_Math"><mml:mrow><mml:mo>±</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.009</mml:mn></mml:mrow></mml:math><tex-math id="IEq84_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm \,0.009$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq84.gif" /></alternatives></inline-formula>), compared to ProtVec (<inline-formula id="IEq85"><alternatives><mml:math id="IEq85_Math"><mml:mrow><mml:mo>-</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.14</mml:mn><mml:mo>±</mml:mo><mml:mn>0.008</mml:mn></mml:mrow></mml:math><tex-math id="IEq85_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-\,0.14 \pm 0.008$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq85.gif" /></alternatives></inline-formula>) and AA sequence (<inline-formula id="IEq86"><alternatives><mml:math id="IEq86_Math"><mml:mrow><mml:mo>-</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.08</mml:mn><mml:mo>±</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math><tex-math id="IEq86_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-\,0.08 \pm 0.001$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq86.gif" /></alternatives></inline-formula>). It is observed that the usage of ProtVec<inline-formula id="IEq87"><alternatives><mml:math id="IEq87_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq87_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq87.gif" /></alternatives></inline-formula> performed better than the others in terms of means and variances with a <italic>p</italic> value &lt; 0.05, while ProtVec and AA sequence did not differ significantly (<italic>p</italic> value is 0.21 and 0.06 for the means and variances respectively (Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Tables S5, S6). It is observed that there are considerable synergy effects of multi-channel for proteins. Therefore, these statistical results indicate that the usage of Mol2vec and ProtVec<inline-formula id="IEq88"><alternatives><mml:math id="IEq88_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq88_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq88.gif" /></alternatives></inline-formula> outperformed the usage of the other features.</p>
              <p id="Par42">The best model was <inline-formula id="IEq89"><alternatives><mml:math id="IEq89_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq89_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq89.gif" /></alternatives></inline-formula> with a z-score of 1.22 (<inline-formula id="IEq90"><alternatives><mml:math id="IEq90_Math"><mml:mrow><mml:mo>±</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.001</mml:mn></mml:mrow></mml:math><tex-math id="IEq90_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm \,0.001$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq90.gif" /></alternatives></inline-formula>), followed by <inline-formula id="IEq91"><alternatives><mml:math id="IEq91_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq91_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq91.gif" /></alternatives></inline-formula> with a z-score of 0.93 (<inline-formula id="IEq92"><alternatives><mml:math id="IEq92_Math"><mml:mrow><mml:mo>±</mml:mo><mml:mspace width="0.166667em" /><mml:mn>0.020</mml:mn></mml:mrow></mml:math><tex-math id="IEq92_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm \,0.020$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq92.gif" /></alternatives></inline-formula>), and <inline-formula id="IEq93"><alternatives><mml:math id="IEq93_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq93_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq93.gif" /></alternatives></inline-formula> with a z-score of 0.75 (± 0.017). It is observed that there were significant differences between the highest model and the lowest model compared to the other models (as can be seen in Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Tables S7, S8). For example, for the Student’s <italic>t</italic> test <inline-formula id="IEq94"><alternatives><mml:math id="IEq94_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq94_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq94.gif" /></alternatives></inline-formula> and <inline-formula id="IEq95"><alternatives><mml:math id="IEq95_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq95_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq95.gif" /></alternatives></inline-formula> were shown to significantly differ from all other models with a <italic>p</italic> value &lt; 0.05. Likewise in variance <inline-formula id="IEq96"><alternatives><mml:math id="IEq96_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq96_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq96.gif" /></alternatives></inline-formula> and <inline-formula id="IEq97"><alternatives><mml:math id="IEq97_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq97_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq97.gif" /></alternatives></inline-formula> were significantly different from the other models with the <italic>p</italic> value &lt; 0.05. So far we have only looked into the highest performance. In the next section we look further into initial performance and the speed of convergence.</p>
            </sec>
          </sec>
          <sec id="Sec8">
            <title>Comparing convergence speed</title>
            <p id="Par43">In addition to the maximum performance, also noticeable are the differences in initial performance and convergence speed between <italic>SCPINN</italic> and <italic>MCPINN</italic>. Initial performance was measured by the performance at the first epoch and the speed of convergence was measured by the actual run time at <inline-formula id="IEq98"><alternatives><mml:math id="IEq98_Math"><mml:mrow><mml:mn>98</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><tex-math id="IEq98_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$98\%$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq98.gif" /></alternatives></inline-formula> of the highest performance of the model. In order to compare the convergence speed of each model more precisely, we mainly measured actual run time and secondarily labeled the number of epochs. For more information about convergence speed against training epochs, refer to the Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Figure S3. The machine specifications for the experiments are described in "<xref rid="Sec11" ref-type="sec">Methods and materials</xref>" section—Hardware used. There are more thresholds that were tested for convergence performance such as <inline-formula id="IEq99"><alternatives><mml:math id="IEq99_Math"><mml:mrow><mml:mn>95</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><tex-math id="IEq99_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$95\%$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq99.gif" /></alternatives></inline-formula>, <inline-formula id="IEq100"><alternatives><mml:math id="IEq100_Math"><mml:mrow><mml:mn>98</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><tex-math id="IEq100_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$98\%$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq100.gif" /></alternatives></inline-formula>, and <inline-formula id="IEq101"><alternatives><mml:math id="IEq101_Math"><mml:mrow><mml:mn>99</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><tex-math id="IEq101_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$99\%$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq101.gif" /></alternatives></inline-formula> in Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S9. The top 3 performing models (<inline-formula id="IEq102"><alternatives><mml:math id="IEq102_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq102_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq102.gif" /></alternatives></inline-formula>, <inline-formula id="IEq103"><alternatives><mml:math id="IEq103_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq103_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq103.gif" /></alternatives></inline-formula>, and <inline-formula id="IEq104"><alternatives><mml:math id="IEq104_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq104_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq104.gif" /></alternatives></inline-formula>) and baseline model (<inline-formula id="IEq105"><alternatives><mml:math id="IEq105_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq105_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq105.gif" /></alternatives></inline-formula>) were compared. Each model showed differences in the number of parameters, training time on an epoch, and the performance but there appears to be no direct correlations between them (as can be seen Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Figures S4 and S5).</p>
            <p id="Par44">It is observed that <italic>MCPINN</italic> performed better than <italic>SCPINN</italic> in terms of initial performance and convergence speed as shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. Initial performance was an MCC of 0.47 ± 0.004 for <inline-formula id="IEq106"><alternatives><mml:math id="IEq106_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq106_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq106.gif" /></alternatives></inline-formula>, 0.43 ± 0.005 for <inline-formula id="IEq107"><alternatives><mml:math id="IEq107_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq107_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq107.gif" /></alternatives></inline-formula>, 0.40 ± 0.003 for <inline-formula id="IEq108"><alternatives><mml:math id="IEq108_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq108_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq108.gif" /></alternatives></inline-formula>, and 0.38 ± 0.016 for <inline-formula id="IEq109"><alternatives><mml:math id="IEq109_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq109_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq109.gif" /></alternatives></inline-formula>. The time it took to reach <inline-formula id="IEq110"><alternatives><mml:math id="IEq110_Math"><mml:mrow><mml:mn>98</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><tex-math id="IEq110_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$98\%$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq110.gif" /></alternatives></inline-formula> of the highest performance was 11 min (18 epochs) for <inline-formula id="IEq111"><alternatives><mml:math id="IEq111_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq111_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq111.gif" /></alternatives></inline-formula>, 41 min (113 epochs) for <inline-formula id="IEq112"><alternatives><mml:math id="IEq112_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq112_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq112.gif" /></alternatives></inline-formula>, 50 min (102 epochs) for <inline-formula id="IEq113"><alternatives><mml:math id="IEq113_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq113_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq113.gif" /></alternatives></inline-formula>, and 55 min (201 epochs) for <inline-formula id="IEq114"><alternatives><mml:math id="IEq114_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq114_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq114.gif" /></alternatives></inline-formula>. <inline-formula id="IEq115"><alternatives><mml:math id="IEq115_Math"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq115_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SC_4$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq115.gif" /></alternatives></inline-formula> and <inline-formula id="IEq116"><alternatives><mml:math id="IEq116_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq116_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_9$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq116.gif" /></alternatives></inline-formula> showed the most contrasting differences in the convergence speed and the highest performance. Even though the former performed a little better than the latter in performance with an MCC of 0.678 versus 0.674, it took 104 min to outperform the latter.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>Comparison of convergence performance between two <italic>MCPINN</italic> and two <italic>SCPINN</italic>. The plot shows the Matthews Correlation Coefficient of models on y-axis against the actual training time in minutes on the x-axis</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig5_HTML.png" id="MO5" /></fig></p>
            <p id="Par45">While the exact cause in these differences cannot be proven, it seems that low-level representations from Dilated CNNs contributed to a non-negligible portion in these differences between the models. Because it is worthwhile examining these differences between the models, let us discuss these phenomena in the perspective of the information bottleneck (IB) theory of deep learning [<xref ref-type="bibr" rid="CR51">51</xref>]. The authors claim that “DNNs undergo two distinct phases which consist of an initial fitting/memorizing phase and a subsequent compression/forgetting phase, which is related to the high generalization performance of DNNs” [<xref ref-type="bibr" rid="CR51">51</xref>]. In this point of view, following explanations can help account for differences in convergence speed: (1) multi-channel architecture can help to construct better representations and reduce the length of two phases because there is little information to be compressed or forgotten. (2) single-channel architecture generally need more training to discover appropriate representations for both fitting phase and compression phase, because there are not enough features. In summary, multi-channel architecture can improve convergence speed as well as the performance.</p>
          </sec>
          <sec id="Sec9">
            <title>Exploring the potential of transfer learning</title>
            <p id="Par46">While this study has focused on representation ability of <italic>MCPINN</italic> in terms of the performance and convergence speed, this section further explores the transferable ability of <italic>MCPINN</italic> to generalize representations from training tasks to related testing tasks. To test whether <italic>MCPINN</italic> can capture general information for compounds and proteins, we pretrained <inline-formula id="IEq118"><alternatives><mml:math id="IEq118_Math"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq118_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MC_2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq118.gif" /></alternatives></inline-formula> on the benchmark dataset and finetuned the model on Tox21 dataset [<xref ref-type="bibr" rid="CR46">46</xref>]. In order to improve the readability of this section, the pretrained models are abbreviated as follows: <inline-formula id="IEq119"><alternatives><mml:math id="IEq119_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq119_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq119.gif" /></alternatives></inline-formula>, where <italic>i</italic> is the number of epochs pretrained on training task, so non-pretrained model is <inline-formula id="IEq120"><alternatives><mml:math id="IEq120_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq120_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_0$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq120.gif" /></alternatives></inline-formula>. <inline-formula id="IEq121"><alternatives><mml:math id="IEq121_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq121_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq121.gif" /></alternatives></inline-formula> was finetuned on the Tox21 training set with early stopping on the validation set and evaluated on the test set, where the Tox21 dataset was split as suggested by DeepChem [<xref ref-type="bibr" rid="CR52">52</xref>].</p>
            <p id="Par47">It should be noted that the two datasets are distinct, where the benchmark dataset is based on biophysics, while the Tox21 dataset is based on physiology [<xref ref-type="bibr" rid="CR53">53</xref>]. The benchmark dataset, obtained from ChEMBL [<xref ref-type="bibr" rid="CR41">41</xref>], focused on bioactivity of small molecules, while Tox21 measured toxicity results in nuclear receptor and stress response pathways in human body. Because Tox21 dataset is strongly imbalanced dataset with the percentage of positives being 7.49% (5957 positives from 79,585 all data points), the performance of models was measured using MCC and Precision–Recall AUC (PRC) instead of ROC, where PRC can provide more accurate prediction when applied to imbalanced classification scenarios [<xref ref-type="bibr" rid="CR54">54</xref>].</p>
            <p id="Par48">To investigate the potential of transferability of <italic>MCPINN</italic>, we have compared the performance of the models pretrained in different epochs in terms of highest performance, initial performance, and convergence speed [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR56">56</xref>]. First, pretrained models performed higher than non-pretrained model. The non-pretrained model <inline-formula id="IEq126"><alternatives><mml:math id="IEq126_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq126_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq126.gif" /></alternatives></inline-formula> had an MCC of 0.43 and a PRC of 0.48 as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. The pretrained models from <inline-formula id="IEq127"><alternatives><mml:math id="IEq127_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>30</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq127_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{30}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq127.gif" /></alternatives></inline-formula> to <inline-formula id="IEq128"><alternatives><mml:math id="IEq128_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>110</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq128_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{110}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq128.gif" /></alternatives></inline-formula> outperformed <inline-formula id="IEq129"><alternatives><mml:math id="IEq129_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq129_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq129.gif" /></alternatives></inline-formula> with a paired <italic>t</italic> test <italic>p</italic> value &lt; 0.05 for both MCC and PRC with an exception of <inline-formula id="IEq130"><alternatives><mml:math id="IEq130_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>85</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq130_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{85}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq130.gif" /></alternatives></inline-formula>, where the <italic>p</italic> value was 0.053 (Additional file <xref ref-type="supplementary-material" rid="MOESM1">1</xref>: Table S10). It is observed that the overall performance of the models rose up to <inline-formula id="IEq131"><alternatives><mml:math id="IEq131_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq131_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq131.gif" /></alternatives></inline-formula> and then declined, where it seems that the decline is because of overfitting on the training task dataset.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>Comparison of finetuning performance between different pretrained models (<inline-formula id="IEq117"><alternatives><mml:math id="IEq117_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq117_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_i$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq117.gif" /></alternatives></inline-formula>), where <italic>i</italic> is the number of pretraining epochs. On the left y-axis the MCC is shown, while on the right y-axis the PRC score is shown against the number of pretraining epochs on x-axis</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig6_HTML.png" id="MO6" /></fig></p>
            <p id="Par49">In contrast, there were small differences in initial performance and convergence speed between the models. We looked into the finetuning phase of the three models including <inline-formula id="IEq132"><alternatives><mml:math id="IEq132_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq132_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq132.gif" /></alternatives></inline-formula>, <inline-formula id="IEq133"><alternatives><mml:math id="IEq133_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq133_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq133.gif" /></alternatives></inline-formula>, and <inline-formula id="IEq134"><alternatives><mml:math id="IEq134_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>135</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq134_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{135}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq134.gif" /></alternatives></inline-formula>, in order to investigate the generalization performance according to the number of pretraining epochs, As shown in Table <xref rid="Tab4" ref-type="table">4</xref> and Fig. <xref rid="Fig7" ref-type="fig">7</xref>, <inline-formula id="IEq135"><alternatives><mml:math id="IEq135_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq135_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq135.gif" /></alternatives></inline-formula> performed slightly better than other models until finetuning epoch 10, but the performance became lower than other models as finetuning continued. For example, initial performance was an MCC of 0.16 ± 0.03 for <inline-formula id="IEq136"><alternatives><mml:math id="IEq136_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq136_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq136.gif" /></alternatives></inline-formula>, 0.11 ± 0.02 for <inline-formula id="IEq137"><alternatives><mml:math id="IEq137_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq137_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq137.gif" /></alternatives></inline-formula>, and 0.08 ± 0.03 for <inline-formula id="IEq138"><alternatives><mml:math id="IEq138_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>135</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq138_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{135}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq138.gif" /></alternatives></inline-formula>. After finetuning epoch 11, <inline-formula id="IEq139"><alternatives><mml:math id="IEq139_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq139_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq139.gif" /></alternatives></inline-formula> started to outperform <inline-formula id="IEq140"><alternatives><mml:math id="IEq140_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq140_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq140.gif" /></alternatives></inline-formula> and <inline-formula id="IEq141"><alternatives><mml:math id="IEq141_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>135</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq141_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{135}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq141.gif" /></alternatives></inline-formula> did so after finetuning epoch 40. In addition to initial performance, it is observed that there were similar performance in convergence speed between models. The number of finetuning epochs to reach 95% of the highest performance was 46 finetuning epochs for <inline-formula id="IEq142"><alternatives><mml:math id="IEq142_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq142_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq142.gif" /></alternatives></inline-formula>, 56 finetuning epochs for <inline-formula id="IEq143"><alternatives><mml:math id="IEq143_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>135</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq143_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{135}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq143.gif" /></alternatives></inline-formula>, and 60 finetuning epochs for <inline-formula id="IEq144"><alternatives><mml:math id="IEq144_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq144_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq144.gif" /></alternatives></inline-formula>.<fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>Comparison of convergence speed between models <inline-formula id="IEq145"><alternatives><mml:math id="IEq145_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq145_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq145.gif" /></alternatives></inline-formula>, where <italic>i</italic> is the number of pretraining epochs. The plot shows the MCC of models on y-axis against the number of finetuning epochs on x-axis. There were small differences in convergence speed between models</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig7_HTML.png" id="MO7" /></fig><table-wrap id="Tab4"><label>Table 4</label><caption xml:lang="en"><p>Comparison performance between different finetuning epochs for models (<inline-formula id="IEq122"><alternatives><mml:math id="IEq122_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq122_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_i$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq122.gif" /></alternatives></inline-formula>)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Models</p></th><th align="left"><p>Finetuning epoch 1</p></th><th align="left"><p>Finetuning epoch 11</p></th><th align="left"><p>Finetuning epoch 40</p></th></tr></thead><tbody><tr><td align="left"><p><inline-formula id="IEq123"><alternatives><mml:math id="IEq123_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>55</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq123_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{55}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq123.gif" /></alternatives></inline-formula></p></td><td char="±" align="char"><p>0.11 ± 0.02</p></td><td char="±" align="char"><p>0.35 ± 0.01</p></td><td char="±" align="char"><p>0.43 ± 0.01</p></td></tr><tr><td align="left"><p><inline-formula id="IEq124"><alternatives><mml:math id="IEq124_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>135</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq124_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{135}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq124.gif" /></alternatives></inline-formula></p></td><td char="±" align="char"><p>0.08 ± 0.03</p></td><td char="±" align="char"><p>0.32 ± 0.02</p></td><td char="±" align="char"><p>0.41 ± 0.02</p></td></tr><tr><td align="left"><p><inline-formula id="IEq125"><alternatives><mml:math id="IEq125_Math"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq125_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$PM_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq125.gif" /></alternatives></inline-formula></p></td><td char="±" align="char"><p>0.16 ± 0.03</p></td><td char="±" align="char"><p>0.34 ± 0.01</p></td><td char="±" align="char"><p>0.40 ± 0.01</p></td></tr></tbody></table></table-wrap></p>
            <p id="Par50">From the results we can see there is still room for improvement. The aim of transfer learning based on PCM methods is high performance with minimum finetuning. Due to the flexibility of PCM method, <italic>MCPINN</italic> can predict any CPI pairs, while the performance without finetuning was poor as can be seen in initial performance of each model. Since there are still a lot of small molecules with only a small amount of bioactivity data, further study of transferring general information covering CPIs space is required.</p>
          </sec>
        </sec>
        <sec id="Sec10" sec-type="conclusions">
          <title>Conclusions</title>
          <p id="Par51">In this paper we proposed a novel multi-channel PINN (<italic>MCPINN</italic>) based on PCM methods to fully utilize CPI data. <italic>MCPINN</italic> utilizes three approaches of DNNs which are a classifier, a feature extractor, and an end-to-end learner to maximize the representation learning ability. We evaluated full combinations of feature pairs to investigate the effects of each pair. We also compared <italic>SCPINN</italic> and <italic>MCPINN</italic> in terms of initial performance and the speed of convergence. In addition to improving the models within a high quality and well balanced dataset, we explored the transferable ability of <italic>MCPINN</italic> to generalize representations from training tasks to related testing tasks, which consist of a strongly imbalanced dataset. To the best of our knowledge, <italic>MCPINN</italic> is the first method to incorporate low and high level representations in a single model.</p>
          <p id="Par52">As discussed above, our results lead to a number of conclusions. For Mol2vec and ProtVec, we suggested that a weighted average operation is a better alternative to the sum operation in representing compounds and proteins. <italic>MCPINN</italic> using the feature pair of ProtVec<inline-formula id="IEq146"><alternatives><mml:math id="IEq146_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq146_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq146.gif" /></alternatives></inline-formula> and Mol2vec outperformed all other models with statistically significant differences. The usage of ProtVec<inline-formula id="IEq147"><alternatives><mml:math id="IEq147_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">AA</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq147_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{AA}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq147.gif" /></alternatives></inline-formula> performed better than others. It suggested that a multi-channel architecture can utilize both channels to capture the order and the content of amino acid sequences. The usage of Mol2vec showed statistically significant differences from the other features for compounds. In particular, the multi-channel models using Mol2vec<inline-formula id="IEq148"><alternatives><mml:math id="IEq148_Math"><mml:msub><mml:mrow /><mml:mrow><mml:mi mathvariant="italic">SS</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq148_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{SS}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq148.gif" /></alternatives></inline-formula> performed worse than the single-channel models using Mol2vec separately. Depending on the combination of compound and protein features, multi-channel models did not guarantee better performance than single-channel models, so a careful selection of representations is required to achieve better performance.</p>
          <p id="Par53">The multi-channel architecture can improve initial performance and convergence speed. It seems that the architecture can help to construct better representations and reduce the length of training phase based on memorizing phase and forgetting phase in terms of IB theory of deep learning. Additionally, we explored the potential of transferability of <italic>MCPINN</italic> in terms of initial performance, speed of convergence, and highest performance. Pretraining on training task improved highest performance, while it did not improve convergence speed and initial performance. It seems that there is room for improvement to transfer the generalized representations from training tasks to test task.</p>
          <p id="Par54">In conclusion, <italic>MCPINN</italic> can improve the representations in terms of initial performance, convergence speed, and highest performance. Moreover, we expect that more biological and molecular information can be utilized as a part of multi-channel for various tasks such as drug discovery, poly-pharmacology, side-effect prediction, and drug resistance.</p>
        </sec>
        <sec id="Sec11" sec-type="materials|methods">
          <title>Methods and materials</title>
          <sec id="Sec12">
            <title>Datasets</title>
            <p id="Par55">A high quality dataset [<xref ref-type="bibr" rid="CR38">38</xref>] was employed as a benchmark dataset for the training task. Fifteen models are evaluated on the benchmark dataset. The dataset covers 0.13% of the total available bioactivity matrix space in ChEMBL, where there are 314,767 observations from 250,412,295 possible data points produced by 204,085 compounds and 1227 protein targets. Percentage of the positives in the dataset is 54.7%. We used Tox21 dataset for the test task in transfer learning. Tox21 dataset has been used in the 2014 Tox21 Data Challenge, where there are 79,585 measurements for 8014 compounds on 12 different targets. Tox21 dataset is strongly imbalanced and the percentage of positives is 7.49%.</p>
            <p id="Par56">DNNs try to minimize differences in the distribution of data between the prediction and target due to the usage of cross entropy as loss function. Therefore, training models on imbalanced data is a challenge. One of the basic solutions is to set higher weights on the positives than the negatives. In addition, it is also difficult to appropriately split the dataset into a training set, a validation set, and a test set. Therefore, we used the data splitting method and the weight value for the positive classes as suggested by Deepchem [<xref ref-type="bibr" rid="CR52">52</xref>].</p>
          </sec>
          <sec id="Sec13">
            <title>High level representation descriptors</title>
            <p id="Par57">We used Extended-Connectivity Fingerprints with diameter of 4 (ECFP4), Mol2vec [<xref ref-type="bibr" rid="CR42">42</xref>], and ProtVec [<xref ref-type="bibr" rid="CR43">43</xref>] to get high level representations. ECFPs is one of the most popular representation in cheminformatics and ECFP4 have shown promising performance among various fingerprints [<xref ref-type="bibr" rid="CR57">57</xref>]. RDkit [<xref ref-type="bibr" rid="CR58">58</xref>] was used for ECFP4 with 1024 dimensional binary vector.</p>
            <p id="Par58">ProtVec and Mol2vec are unsupervised machine learning approaches for embedding proteins and compounds. These algorithm are inspired by a technique called Word2Vec [<xref ref-type="bibr" rid="CR59">59</xref>] in Natural Language Processing (NLP). As a metaphor by NLP, molecules and proteins are considered as sentences. Morgan substructures and N-gram amino acid sequences are considered as “words”, and large-scale databases such as ZINC [<xref ref-type="bibr" rid="CR44">44</xref>], ChEMBL [<xref ref-type="bibr" rid="CR41">41</xref>] and UniProt [<xref ref-type="bibr" rid="CR45">45</xref>] are considered as large corpus datasets.</p>
            <p id="Par59">For the protein embedding model, we train the embedding model on protein sets obtained from UniProt (release 2017_09) and ChEMBL (version 23). All duplicate sequence and same protein id with various amino sequences are removed. The number of sequences for training embedding model is 553,195. The embedding model is based on Skip-gram model and the model is trained with following hyperparameters: dimension of the representation is 300, window size is 35, and minimum count is 2. In Tox21, the target “SR-MMP” has no amino acid sequences, so the embedding value is zeros. Molecular corpus dataset, obtained from ZINC and ChEMBL (version 23), contains about 19.9 million compounds using the approach suggested in [<xref ref-type="bibr" rid="CR42">42</xref>], and we used a pretrained embedding model the authors proposed.</p>
            <p id="Par60">Embedded sentences are composed of the group of embedded words. We build two types of weighted average methods, which are arithmetic mean and TF-IDF weighted average method, to refine the original sum method. The original sum method is as followed:<disp-formula id="Equ1"><alternatives><mml:math display="block" id="Equ1_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">sum</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} S^{sum} = \sum \limits _{i=1}^N w_{i} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_Equ1.gif" /></alternatives></disp-formula>where <inline-formula id="IEq149"><alternatives><mml:math id="IEq149_Math"><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">sum</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq149_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S^{sum}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq149.gif" /></alternatives></inline-formula> is a embedded sentence produced by the method, <italic>N</italic> is the number of words in the sentence, and <inline-formula id="IEq150"><alternatives><mml:math id="IEq150_Math"><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq150_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq150.gif" /></alternatives></inline-formula> is a <italic>i</italic>th embedded word in the sentence. However, the number of sum operations is dependent on <italic>N</italic> of each sentence, so it can alter the embedded sentence, regardless of the actual meaning of the sentence. Instead, arithmetic mean method is as followed:<disp-formula id="Equ2"><alternatives><mml:math display="block" id="Equ2_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">mean</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} S^{mean} = \frac{1}{N} \sum \limits _{i=1}^N w_{i} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_Equ2.gif" /></alternatives></disp-formula>where <inline-formula id="IEq151"><alternatives><mml:math id="IEq151_Math"><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">mean</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq151_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S^{mean}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq151.gif" /></alternatives></inline-formula> is a embedded sentence produced by the method. This method divides each word by the length of the sentence. Therefore, the same word can have different embedded value in each sentence due to the differences in length.</p>
            <p id="Par61">Moreover, TF-IDF [<xref ref-type="bibr" rid="CR47">47</xref>] weighted average method is as followed:<disp-formula id="Equ3"><alternatives><mml:math display="block" id="Equ3_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>t</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} S^{tf{-}idf} = \sum \limits _{i=1}^N t_{w} w_{i} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_Equ3.gif" /></alternatives></disp-formula>where <inline-formula id="IEq152"><alternatives><mml:math id="IEq152_Math"><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq152_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S^{tf{-}idf}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq152.gif" /></alternatives></inline-formula> is a embedded sentence produced by the method and <inline-formula id="IEq153"><alternatives><mml:math id="IEq153_Math"><mml:msub><mml:mi>t</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math><tex-math id="IEq153_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_w$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq153.gif" /></alternatives></inline-formula> stands for TF-IDF weight value for a word <italic>w</italic>. This method sets the importance of each word by TF-IDF, so the same word has same embedded value in every sentence. To calculate weight value of TF-IDF, scikit-learn (version 0.19) is used based on compounds and proteins in benchmark dataset and Tox21.</p>
          </sec>
          <sec id="Sec14">
            <title>Low level representation descriptors</title>
            <p id="Par62">We used low-level representation data for end-to-end learning models, where they are amino acid sequences for proteins and SMILES strings for compounds. Both sequences were tokenized and then encoded into one-hot binary vector with fixed length. Tokenizing process produced 24 single characters from the proteins and 57 single characters for SMILES as suggested in [<xref ref-type="bibr" rid="CR60">60</xref>], where the characters are extracted from benchmark dataset and the Tox21 dataset. The tokenized strings were converted into one-hot encoded representations, which assign the corresponding single token to one and the others to zero. In order to use the sequences as an input for the machine learning model, we set the sequences to a fixed length with post truncation or zero-padding. If the sequences are longer than the fixed length, they are trimmed by removing from the end of sequences to the fixed length, unless they are filled with zero from the end of the sequences to the fixed length. In determining the fixed length of sequences, there is a trade-off between information preservation and computational efficiency. We chose the fixed length 100 for compounds and 700 for proteins, where a percentile of 75% for SMILES strings is 63.0 and a percentile of 75% for amino acid sequences is 712.2 as shown in Figs. <xref rid="Fig8" ref-type="fig">8</xref> and <xref rid="Fig9" ref-type="fig">9</xref>.<fig id="Fig8"><label>Fig. 8</label><caption xml:lang="en"><p>SMILES string length distribution</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig8_HTML.png" id="MO11" /></fig><fig id="Fig9"><label>Fig. 9</label><caption xml:lang="en"><p>Amino acid sequence length distribution</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/13321_2019_368_Fig9_HTML.png" id="MO12" /></fig></p>
          </sec>
          <sec id="Sec15">
            <title>Transfer learning</title>
            <p id="Par64">Transfer learning focuses on whether machine learning model can transfer generalized representations from training tasks to a different but related test tasks. While there are several factors that affect finetuning methods, two important factors are generally considered [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR56">56</xref>]. The factors are the size of the test task’s dataset (i.e. small or large) and similarity of test task (i.e. the content of data or classes and balance of data or classes). There are four basic strategies to finetune the pretrained models on test tasks as followed: (1) If the dataset of test task is large and the task is very similar to training task, finetuning full networks is suggested since the risk of overfitting is low. This case is expected to demonstrate promising performance. (2) If the dataset of test task is large and the task is very different from the training task, there are two options which are finetuning full networks or not pretraining the model on the training dataset. In practice, it is suggested to finetune the full networks to reduce training time. (3) If the dataset of test task is small and the task is very similar to the training task, finetuning full networks is not suggested due to the risk of overfitting. Instead, it is suggested to finetune the simple classifier to avoid overfitting. (4) If the dataset of test task is small and the task is very different from the training task, a simple classifier is not suggested due to the differences between tasks. It is suggested to initialize the top layers and freeze the other layers to finetune the layers and classifier, since the top layers contain more task-specific representations.</p>
            <p id="Par65">The benchmark dataset is four times larger than Tox21 dataset and the tasks are different in terms of biophysics versus physiology as categorized in [<xref ref-type="bibr" rid="CR53">53</xref>]. Moreover, the benchmark dataset is balanced, while Tox21 dataset is strongly imbalanced, where the percentage of positives is 7.49% (5957 positives from 79,585 all data points). Therefore, this study corresponds to the fourth scenario. We pretrained the models on training dataset and then finetuned the pretrained models for every 5 pretraining epoch. The pretraining epoch is 140 and finetuning epoch is 200 with early stopping.</p>
          </sec>
          <sec id="Sec16">
            <title>DNNs</title>
            <p id="Par66">All DNN models are created using Keras [<xref ref-type="bibr" rid="CR61">61</xref>] and Tensorflow [<xref ref-type="bibr" rid="CR62">62</xref>]. We tested various architectures, parameters, and hyperparameters to optimize DNN models in initial cross-validation phase as shown in Table <xref rid="Tab5" ref-type="table">5</xref>. All tested models were validated with five-fold cross-validation on validation data (20% of training data) for 400 epochs with early stopping in order to find the optimal network configuration. Then the optimal model was trained on the full training data and evaluated on test data.<table-wrap id="Tab5"><label>Table 5</label><caption xml:lang="en"><p>Architectures, parameters, and hyperparameters explored for DNNs</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Base model</p></th><th align="left" /><th align="left"><p>Value</p></th><th align="left"><p>Description</p></th></tr></thead><tbody><tr><td align="left" rowspan="3"><p>PINN</p></td><td align="left"><p>Separated layers</p></td><td align="left"><p>1, 2, 3, 4</p></td><td align="left"><p>The number of separated layers for PINN</p></td></tr><tr><td align="left"><p>Concatenated layers</p></td><td align="left"><p>1, 2</p></td><td align="left"><p>The number of concatenated layers for PINN</p></td></tr><tr><td align="left"><p>Number of nodes</p></td><td align="left"><p>256, 512, 1024, 2048</p></td><td align="left"><p>The number of nodes for layers</p></td></tr><tr><td align="left" rowspan="3"><p>Dilated CNN</p></td><td align="left"><p>Filters</p></td><td align="left"><p>4, 8, 16, 32</p></td><td align="left"><p>The number of filters for Dilated CNN</p></td></tr><tr><td align="left"><p>Kernel size</p></td><td align="left"><p>6, 8, 12, 22</p></td><td align="left"><p>The length of the convolution window for Dilated CNN</p></td></tr><tr><td align="left"><p>Embedding</p></td><td align="left"><p>16, 32</p></td><td align="left"><p>Dimension of dense embedding for low level representations</p></td></tr><tr><td align="left"><p>LSTM, BLSTM</p></td><td align="left"><p>Units</p></td><td align="left"><p>128, 256</p></td><td align="left"><p>The units to represent hidden layers for RNN</p></td></tr><tr><td align="left" rowspan="9"><p>DNN</p></td><td align="left"><p>Lr</p></td><td align="left"><p>0.0005</p></td><td align="left"><p>Initial learning rate</p></td></tr><tr><td align="left"><p>Initializer</p></td><td align="left"><p><inline-formula id="IEq154"><alternatives><mml:math id="IEq154_Math"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>-</mml:mo><mml:msqrt><mml:mrow><mml:mn>3</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>,</mml:mo><mml:msqrt><mml:mrow><mml:mn>3</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="IEq154_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[ - \sqrt{ 3 / fan_{in}}, \sqrt{ 3 / fan_{in}}]$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq154.gif" /></alternatives></inline-formula></p></td><td align="left"><p>Initial weight value called Lecun uniform distribution</p></td></tr><tr><td align="left"><p>Optimizer</p></td><td align="left"><p>Adam</p></td><td align="left"><p>Optimizer for stochastic gradient descent</p></td></tr><tr><td align="left"><p>Weight decay</p></td><td align="left"><p>0.0, 0.00001</p></td><td align="left"><p>Learning rate decay over each update</p></td></tr><tr><td align="left"><p>Activation function</p></td><td align="left"><p>ReLU, ELU</p></td><td align="left"><p>Neuron activation function</p></td></tr><tr><td align="left"><p>Drop out</p></td><td align="left"><p>0.25, 0.5</p></td><td align="left"><p>The rate of drop out</p></td></tr><tr><td align="left"><p>Batch</p></td><td align="left"><p>1024</p></td><td align="left"><p>Batch size for training</p></td></tr><tr><td align="left"><p>Epochs_training</p></td><td align="left"><p>400</p></td><td align="left"><p>Training epochs on a training task</p></td></tr><tr><td align="left"><p>Epochs_finetune</p></td><td align="left"><p>200</p></td><td align="left"><p>Finetuning epochs for a pretrained model on a test task</p></td></tr></tbody></table></table-wrap></p>
            <p id="Par67"><italic>Adam</italic> is generally used in DNNs due to efficient and fast training performance because the step size is not affected by the value of the gradient. We used the hyperparameters 0.9 for <inline-formula id="IEq155"><alternatives><mml:math id="IEq155_Math"><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="IEq155_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta _1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq155.gif" /></alternatives></inline-formula> and 0.999 for <inline-formula id="IEq156"><alternatives><mml:math id="IEq156_Math"><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="IEq156_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta _2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq156.gif" /></alternatives></inline-formula> as suggested [<xref ref-type="bibr" rid="CR63">63</xref>]. However, learning rate was 0.0005 and weight decay was not zero to achieve more stable training, where weight decay reduces the learning rate over each update. Since the benchmark dataset is very sparse, small batch size can mislead the training model to local optimum. Therefore, we set mini-batch size 1024 for the generalized performance as suggested [<xref ref-type="bibr" rid="CR64">64</xref>]. All weights and biases were initialized from a uniform distribution within <inline-formula id="IEq157"><alternatives><mml:math id="IEq157_Math"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>-</mml:mo><mml:msqrt><mml:mrow><mml:mn>3</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>,</mml:mo><mml:msqrt><mml:mrow><mml:mn>3</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="IEq157_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[ - \sqrt{ 3 / fan_{in}}, \sqrt{ 3 / fan_{in}}]$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq157.gif" /></alternatives></inline-formula>, where <inline-formula id="IEq158"><alternatives><mml:math id="IEq158_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="IEq158_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$fan_{in}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq158.gif" /></alternatives></inline-formula> is the number of input units in the weights, which is called Lecun uniform distribution. Lecun uniform distribution performed better than random uniform distribution and truncated normal distribution in terms of performance and convergence speed, because it leads to efficient backpropagation calculations [<xref ref-type="bibr" rid="CR65">65</xref>].</p>
            <p id="Par68">Rectified linear (ReLU) units are commonly used in DNNs because they do not suffer from vanishing gradient and their training speed is fast. However, ReLU units ignore the negative values, so there is information loss called “dying ReLU” [<xref ref-type="bibr" rid="CR66">66</xref>]. Exponential linear units (ELU) [<xref ref-type="bibr" rid="CR67">67</xref>] was introduced to solve the problem. ELU and ReLU are in identity function form for non-negative inputs, but for negative inputs, they are different, where if <inline-formula id="IEq159"><alternatives><mml:math id="IEq159_Math"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="IEq159_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x &lt;0$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq159.gif" /></alternatives></inline-formula>, <inline-formula id="IEq160"><alternatives><mml:math id="IEq160_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq160_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(x)= \alpha (e^x-1)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq160.gif" /></alternatives></inline-formula> for ELU and <inline-formula id="IEq161"><alternatives><mml:math id="IEq161_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="IEq161_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(x)=0$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq161.gif" /></alternatives></inline-formula> for ReLU. ELU can capture information in the negative value. Therefore, we used following parameters for the final DNN models: (1) as an optimizer <italic>Adam</italic> with 0.9 beta 1 and 0.999 beta 2 is used as suggested [<xref ref-type="bibr" rid="CR63">63</xref>], (2) learning rate is 0.0005, (3) number of epochs is 500, (4) mini-batch size is 1024, (5) Lecun uniform distribution, (6) the weight decay is 0.00001, (7) activation function is ELU.</p>
            <sec id="Sec17">
              <title>DNNs: end-to-end learning</title>
              <p id="Par69">We built three types of end-to-end DNNs based on convolution neural networks (CNN) and recurrent neural networks (RNN). RNN is designed to learn sequential data and CNN has multiple filters which are incorporated with each other to discover various representations. These model have shown promising performance for sequential data in various domains. Among RNN models, long short-term memory (LSTM) [<xref ref-type="bibr" rid="CR68">68</xref>] and bidirectional LSTM (BLSTM) [<xref ref-type="bibr" rid="CR69">69</xref>] have outperformed conventional models (i.e. Hidden Markov model) and recent proposed models (i.e. Gated Recurrent Unit) over two decades [<xref ref-type="bibr" rid="CR70">70</xref>]. LSTM is a recurrent neural network model with explicit memory cell. Due to the memory cell, LSTM can remember or forget long-term dependencies needed for tasks. The memory cell is carefully regulated by four modules, which are input gate, forget gate, output gate, and cell update. Bidirectional LSTM (BLSTM) is a variant version of LSTM. BLSTM has two LSTMs which go in opposite directions, forward and backward. The two features complement each other and contribute to performance improvement.</p>
              <p id="Par70">We used dilated convolution neural networks (Dilated CNN) [<xref ref-type="bibr" rid="CR71">71</xref>] among end-to-end learners. Dilated CNN is a convolution neural networks with skip layers. Conventional CNN learns long-term dependency by reducing the size of the data, but it results in information loss. In contrast, Dilated CNN can learn long-term dependency efficiently with skip layers. The layers have wider receptive fields compared to conventional layers. The size of kernel is the length of the convolution window and it affects the long-term dependency of given sequences. The basic suggestion is a small kernel size (i.e. 3) to achieve efficient training and less number of parameters [<xref ref-type="bibr" rid="CR72">72</xref>]. However, we chose larger size of kernel, since ProtVec and Mol2vec already captured the features in terms of local perspective.</p>
              <p id="Par71">The number of filters determines depth of the output volume called feature map, which is the result of the convolution layer. If the number of filters is too large the model can suffer from overfitting, otherwise the model can suffer from underfitting. In computer vision domain, the number of filter is large but we tested smaller numbers of filter due to the sparseness of CPI data space. The embedding layer is the first layer for one-hot encoded vectors. The dimension size 32 and 16 was tested, but there were little differences in performance. Therefore, the final value of network architecture and hyperparameters for Dilated CNNs were (1) the number of filters is 16, (2) the kernel size is 12, (3) an embedding layer with 16 dimension is used to reduce the number of parameters, and (4) valid padding to reduce the shape of the feature maps in each layers.</p>
              <p id="Par72">For LSTM and BLSTM, the final value of network architecture and hyperparameters were: (1) units are 256, which is the dimensionality of output, (2) set forget bias as suggested [<xref ref-type="bibr" rid="CR73">73</xref>].</p>
            </sec>
            <sec id="Sec18">
              <title>DNNs: pairwise input neural networks</title>
              <p id="Par73">Pairwise input neural network (PINN) is used for <italic>MCPINN</italic> and <italic>SCPINN</italic>. PINN is a variation of feedforward neural networks and is a more suitable architecture for PCM methods. It consists of separated layers with two input and concatenated layers. For <italic>MCPINN</italic>, all channels are merged in the concatenated layer as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Since the separated layers are independently composed without connection from other layers, each input channel layers build representations independently for each input. Moreover, the architecture can balance the ratio of each feature by controlling the number of nodes in the last separated layers. For example, although the input dimension of ECFP is 1024 and the input dimension of ProtVec is 300, the dimension of each representation is the number of nodes in the last separated layers. In contrast, DNNs can be biased to the feature of larger input dimensions.</p>
              <p id="Par74">We normalized the high-level representations with zero mean and unit variance to achieve stable training, because outliers can degrade the performance of machine learning algorithms in terms of prediction, learning speed, and the convergence of the algorithms. In particular, many gradient based algorithms (i.e. deep learning) are often designed with the assumption that input data is nearly standardized data, which is generally obtained by subtracting the mean and scaling the data to unit variance. We tested separated layers from 1 to 4 and concatenated layer from 1 to 2. The number of concatenated layer is 1 for both <italic>SCPINN</italic> and <italic>MCPINN</italic>, but the number of each separated layers is 2 for <italic>SCPINN</italic> and 1 for <italic>MCPINN</italic> to reduce overfitting, where the parameters of end-to-end channel was added in <italic>MCPINN</italic>. To prevent overfitting, we used 10% dropout on initial layer and 50% on hidden layers and early stopping.</p>
              <p id="Par75">In our experiments, the final value of network architecture and hyperparameters for PINN were: (1) the number of each separated layers is 2 for <italic>SCPINN</italic> and 1 for <italic>MCPINN</italic>, (2) the number of each concatenated layer is 1, (3) the number of units in each separated layer is 1024 and 256, (4) the number of units in each concatenated layer is 256, (5) dropout rate is 0.5 (6) each features are normalized with zero mean and unit variance.</p>
            </sec>
          </sec>
          <sec id="Sec19">
            <title>Performance metrics</title>
            <p id="Par76">For the performance evaluation, we used three metrics, which are Matthew Correlation Coefficient (MCC), Receiver Operating Characteristic Area Under the Curve (ROC), and Precision–Recall Area Under the Curve (PRC). Above metrics are commonly used in binary classification to evaluate the quality of the performance. ROC space is determined by the false positive rate (FPR) versus true positive rate (TPR) called recall as x and y axis, where FPR and TPR is calculated by following formula: <inline-formula id="IEq162"><alternatives><mml:math id="IEq162_Math"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq162_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$TPR = TP / (TP+FN)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq162.gif" /></alternatives></inline-formula> and <inline-formula id="IEq163"><alternatives><mml:math id="IEq163_Math"><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq163_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FPR = FP/(FP+TN)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq163.gif" /></alternatives></inline-formula>, where <italic>TP</italic> is the number of true positives, <italic>FN</italic> the number of false negatives, <italic>FP</italic> the number of false positives, and <italic>TN</italic> the number of true negatives. It means ROC shows relative trade-offs between true positive and false positive. The value of ROC is between 0 and + 1, where + 1 indicated perfect prediction, 0.5 means random prediction, and 0 indicates totally wrong prediction.</p>
            <p id="Par77">PRC can provide more accurate prediction when applied to imbalanced classification scenario than ROC, because PRC put more importance on the TPR in case of imbalanced dataset. ROC and PRC share TPR (recall) on same axis, but PRC uses precision for the other axis, where precision is calculated by following formula: <inline-formula id="IEq164"><alternatives><mml:math id="IEq164_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq164_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$precision = TP / (FP+TP)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq164.gif" /></alternatives></inline-formula>. MCC is generally regarded as being one of the best metrics because MCC is more useful than other metrics when the two classes are very different. MCC is calculated by following formula:<disp-formula id="Equ4"><alternatives><mml:math display="block" id="Equ4_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \frac{TP \times TN - FP \times FN }{ \sqrt{ (TP+FP)(TP+FN)(TN+FP)(TN+FN)}} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_Equ4.gif" /></alternatives></disp-formula>The value of MCC is between <inline-formula id="IEq165"><alternatives><mml:math id="IEq165_Math"><mml:mrow><mml:mo>-</mml:mo><mml:mspace width="0.166667em" /><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="IEq165_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-\,1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="13321_2019_368_Article_IEq165.gif" /></alternatives></inline-formula> and + 1, where + 1 indicates perfect prediction, 0 means random prediction, and − 1 represents totally wrong prediction.</p>
          </sec>
          <sec id="Sec20">
            <title>Software used</title>
            <p id="Par78">Python (version 2.7) was used with the following libraries: Keras (version 2.2.0) and Tensorflow (1.9.0) for the neural networks, RDKit (version 2017.03.3) for the calculation of the fingerprints and descriptors, scikit-learn (version 0.19) for splitting validation, normalization and performance evaluation, SciPy (version 1.2.0) for statistical analysis including students <italic>t</italic> test and Fisher F test, ProtVec for the protein descriptors, and Mol2vec for the molecule descriptors.</p>
          </sec>
          <sec id="Sec21">
            <title>Hardware used</title>
            <p id="Par79">A Linux server running Ubuntu 16.04 was established for experiments. The server was equipped with a Xeon E5-2620 v4 processor, 96 GB RAM, and four NVIDIA GeForce GTX 1080 Ti for Graphics Processing Units.</p>
          </sec>
        </sec>
      </body>
      <back>
        <ack>
          <title>Acknowledgements</title>
          <p>The manuscript was proofread by the Dental Research Institute of Seoul National University. Munhwan Lee wants to thank Suresh Manandhar for fruitful discussions they had. Munhwan Lee also wants to thank Yongju Lee for designing Fig. <xref rid="Fig1" ref-type="fig">1</xref>.</p>
        </ack>
        <sec sec-type="author-contribution">
          <title>Authors' contributions</title>
          <p>H-GK supervised the whole process of this work. ML and H-GK conceived this work. ML and H-GK developed the prediction methods. ML and HK performed the experimental work and analysis. ML, HK, and HJ wrote the manuscript. All authors read and approved the final manuscript.</p>
        </sec>
        <sec>
          <title>Funding</title>
          <p>This work was partly supported by Institute for Information and Communications Technology Promotion (IITP) Grant funded by the Korea Government (MSIP) (No. 2017-0-00398, Development of drug discovery software based on big data) and the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT and future Planning (No. NRF-2017R1A2B2008729).</p>
        </sec>
        <sec sec-type="data-availability">
          <title>Availability of data and materials</title>
          <p>The source code and data supporting the conclusions of this article are available in the following link: <ext-link xlink:href="https://github.com/mhlee0903/multi_channels_PINN.git" ext-link-type="uri">https://github.com/mhlee0903/multi_channels_PINN.git</ext-link>.</p>
        </sec>
        <sec sec-type="ethics-statement">
          <sec id="FPar2" sec-type="COI-statement">
            <title>Competing interests</title>
            <p id="Par82">The authors declare that they have no competing interests.</p>
          </sec>
        </sec>
        <ref-list id="Bib1">
          <title>References</title>
          <ref-list>
            <ref id="CR1">
              <label>1.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Rifaioglu</surname>
                    <given-names>AS</given-names>
                  </name>
                  <name>
                    <surname>Atas</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Martin</surname>
                    <given-names>MJ</given-names>
                  </name>
                  <name>
                    <surname>Cetin-Atalay</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Atalay</surname>
                    <given-names>V</given-names>
                  </name>
                  <name>
                    <surname>Doğan</surname>
                    <given-names>T</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Recent applications of deep learning and machine intelligence on in silico drug discovery: methods, tools and databases</article-title>
                <source>Brief Bioinform</source>
                <year>2018</year>
                <volume>10</volume>
                <fpage>1</fpage>
                <lpage>36</lpage>
              </mixed-citation>
            </ref>
            <ref id="CR2">
              <label>2.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Chen</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Liu</surname>
                    <given-names>X</given-names>
                  </name>
                  <name>
                    <surname>Jin</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Lin</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Liu</surname>
                    <given-names>J</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Machine learning for drug–target interaction prediction</article-title>
                <source>Molecules</source>
                <year>2018</year>
                <volume>23</volume>
                <issue>9</issue>
                <fpage>2208</fpage>
                <pub-id pub-id-type="pmcid">6225477</pub-id>
                <pub-id pub-id-type="doi">10.3390/molecules23092208</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitVahtrfM</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR3">
              <label>3.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Ding</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Takigawa</surname>
                    <given-names>I</given-names>
                  </name>
                  <name>
                    <surname>Mamitsuka</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Zhu</surname>
                    <given-names>S</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Similarity-based machine learning methods for predicting drug–target interactions: a brief review</article-title>
                <source>Brief Bioinform</source>
                <year>2013</year>
                <volume>15</volume>
                <issue>5</issue>
                <fpage>734</fpage>
                <lpage>747</lpage>
                <pub-id pub-id-type="pmid">23933754</pub-id>
                <pub-id pub-id-type="doi">10.1093/bib/bbt056</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR4">
              <label>4.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Kim</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Thiessen</surname>
                    <given-names>PA</given-names>
                  </name>
                  <name>
                    <surname>Bolton</surname>
                    <given-names>EE</given-names>
                  </name>
                  <name>
                    <surname>Chen</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Fu</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>Gindulyte</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Han</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>He</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>He</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Shoemaker</surname>
                    <given-names>BA</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Pubchem substance and compound databases</article-title>
                <source>Nucleic Acids Res</source>
                <year>2015</year>
                <volume>44</volume>
                <issue>D1</issue>
                <fpage>1202</fpage>
                <lpage>1213</lpage>
                <pub-id pub-id-type="doi">10.1093/nar/gkv951</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXhtV2gu7bE</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR5">
              <label>5.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Walters</surname>
                    <given-names>WP</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Virtual chemical libraries: miniperspective</article-title>
                <source>J Med Chem</source>
                <year>2018</year>
                <volume>62</volume>
                <issue>3</issue>
                <fpage>1116</fpage>
                <lpage>1124</lpage>
                <pub-id pub-id-type="pmid">30148631</pub-id>
                <pub-id pub-id-type="doi">10.1021/acs.jmedchem.8b01048</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhsFyqtbnM</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR6">
              <label>6.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Ruddigkeit</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Van Deursen</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Blum</surname>
                    <given-names>LC</given-names>
                  </name>
                  <name>
                    <surname>Reymond</surname>
                    <given-names>J-L</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17</article-title>
                <source>J Chem Inf Model</source>
                <year>2012</year>
                <volume>52</volume>
                <issue>11</issue>
                <fpage>2864</fpage>
                <lpage>2875</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhsFClsL3J</pub-id>
                <pub-id pub-id-type="pmid">23088335</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci300415d</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR7">
              <label>7.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Consortium</surname>
                    <given-names>U</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Uniprot: a hub for protein information</article-title>
                <source>Nucleic Acids Res</source>
                <year>2014</year>
                <volume>43</volume>
                <issue>D1</issue>
                <fpage>204</fpage>
                <lpage>212</lpage>
                <pub-id pub-id-type="doi">10.1093/nar/gku989</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXhtVymtb%2FM</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR8">
              <label>8.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Cao</surname>
                    <given-names>D-S</given-names>
                  </name>
                  <name>
                    <surname>Liu</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Xu</surname>
                    <given-names>Q-S</given-names>
                  </name>
                  <name>
                    <surname>Lu</surname>
                    <given-names>H-M</given-names>
                  </name>
                  <name>
                    <surname>Huang</surname>
                    <given-names>J-H</given-names>
                  </name>
                  <name>
                    <surname>Hu</surname>
                    <given-names>Q-N</given-names>
                  </name>
                  <name>
                    <surname>Liang</surname>
                    <given-names>Y-Z</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Large-scale prediction of drug–target interactions using protein sequences and drug topological structures</article-title>
                <source>Anal Chim Acta</source>
                <year>2012</year>
                <volume>752</volume>
                <fpage>1</fpage>
                <lpage>10</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhsFWiurrO</pub-id>
                <pub-id pub-id-type="pmid">23101647</pub-id>
                <pub-id pub-id-type="doi">10.1016/j.aca.2012.09.021</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR9">
              <label>9.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Gönen</surname>
                    <given-names>M</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Predicting drug–target interactions from chemical and genomic kernels using bayesian matrix factorization</article-title>
                <source>Bioinformatics</source>
                <year>2012</year>
                <volume>28</volume>
                <issue>18</issue>
                <fpage>2304</fpage>
                <lpage>2310</lpage>
                <pub-id pub-id-type="pmid">22730431</pub-id>
                <pub-id pub-id-type="doi">10.1093/bioinformatics/bts360</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhtlanurnI</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR10">
              <label>10.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Scior</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Bender</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Tresadern</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>Medina-Franco</surname>
                    <given-names>JL</given-names>
                  </name>
                  <name>
                    <surname>Martínez-Mayorga</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Langer</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Cuanalo-Contreras</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Agrafiotis</surname>
                    <given-names>DK</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Recognizing pitfalls in virtual screening: a critical review</article-title>
                <source>J Chem Inf Model</source>
                <year>2012</year>
                <volume>52</volume>
                <issue>4</issue>
                <fpage>867</fpage>
                <lpage>881</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38Xkt1eiurg%3D</pub-id>
                <pub-id pub-id-type="pmid">22435959</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci200528d</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR11">
              <label>11.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Reymond</surname>
                    <given-names>J-L</given-names>
                  </name>
                  <name>
                    <surname>Van Deursen</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Blum</surname>
                    <given-names>LC</given-names>
                  </name>
                  <name>
                    <surname>Ruddigkeit</surname>
                    <given-names>L</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Chemical space as a source for new drugs</article-title>
                <source>MedChemComm</source>
                <year>2010</year>
                <volume>1</volume>
                <issue>1</issue>
                <fpage>30</fpage>
                <lpage>38</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3cXhtVeju7rF</pub-id>
                <pub-id pub-id-type="doi">10.1039/c0md00020e</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR12">
              <label>12.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Li</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Gao</surname>
                    <given-names>Z</given-names>
                  </name>
                  <name>
                    <surname>Kang</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Zhang</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Yang</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Yu</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Luo</surname>
                    <given-names>X</given-names>
                  </name>
                  <name>
                    <surname>Zhu</surname>
                    <given-names>W</given-names>
                  </name>
                  <name>
                    <surname>Chen</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Shen</surname>
                    <given-names>J</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Tarfisdock: a web server for identifying drug targets with docking approach</article-title>
                <source>Nucleic Acids Res</source>
                <year>2006</year>
                <volume>34</volume>
                <issue>suppl–2</issue>
                <fpage>219</fpage>
                <lpage>224</lpage>
                <pub-id pub-id-type="doi">10.1093/nar/gkl114</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD28Xps1yit7s%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR13">
              <label>13.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Xie</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Evangelidis</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Xie</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Bourne</surname>
                    <given-names>PE</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Drug discovery using chemical systems biology: weak inhibition of multiple kinases may contribute to the anti-cancer effect of nelfinavir</article-title>
                <source>PLoS Comput Biol</source>
                <year>2011</year>
                <volume>7</volume>
                <issue>4</issue>
                <fpage>1002037</fpage>
                <pub-id pub-id-type="doi">10.1371/journal.pcbi.1002037</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXlsl2nsrw%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR14">
              <label>14.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Yang</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Wang</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Chen</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Jegga</surname>
                    <given-names>AG</given-names>
                  </name>
                  <name>
                    <surname>Luo</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Shi</surname>
                    <given-names>L</given-names>
                  </name>
                  <name>
                    <surname>Wan</surname>
                    <given-names>C</given-names>
                  </name>
                  <name>
                    <surname>Guo</surname>
                    <given-names>X</given-names>
                  </name>
                  <name>
                    <surname>Qin</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>He</surname>
                    <given-names>G</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Exploring off-targets and off-systems for adverse drug reactions via chemical-protein interactome—clozapine-induced agranulocytosis as a case study</article-title>
                <source>PLoS Comput Biol</source>
                <year>2011</year>
                <volume>7</volume>
                <issue>3</issue>
                <fpage>1002016</fpage>
                <pub-id pub-id-type="doi">10.1371/journal.pcbi.1002016</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXkvVeqsr0%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR15">
              <label>15.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Keiser</surname>
                    <given-names>MJ</given-names>
                  </name>
                  <name>
                    <surname>Roth</surname>
                    <given-names>BL</given-names>
                  </name>
                  <name>
                    <surname>Armbruster</surname>
                    <given-names>BN</given-names>
                  </name>
                  <name>
                    <surname>Ernsberger</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>Irwin</surname>
                    <given-names>JJ</given-names>
                  </name>
                  <name>
                    <surname>Shoichet</surname>
                    <given-names>BK</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Relating protein pharmacology by ligand chemistry</article-title>
                <source>Nat Biotechnol</source>
                <year>2007</year>
                <volume>25</volume>
                <issue>2</issue>
                <fpage>197</fpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2sXhtlOrsLo%3D</pub-id>
                <pub-id pub-id-type="pmid">17287757</pub-id>
                <pub-id pub-id-type="doi">10.1038/nbt1284</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR16">
              <label>16.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Campillos</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Kuhn</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Gavin</surname>
                    <given-names>A-C</given-names>
                  </name>
                  <name>
                    <surname>Jensen</surname>
                    <given-names>LJ</given-names>
                  </name>
                  <name>
                    <surname>Bork</surname>
                    <given-names>P</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Drug target identification using side-effect similarity</article-title>
                <source>Science</source>
                <year>2008</year>
                <volume>321</volume>
                <issue>5886</issue>
                <fpage>263</fpage>
                <lpage>266</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXot1entbY%3D</pub-id>
                <pub-id pub-id-type="pmid">18621671</pub-id>
                <pub-id pub-id-type="doi">10.1126/science.1158140</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR17">
              <label>17.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Koutsoukas</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Simms</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Kirchmair</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Bond</surname>
                    <given-names>PJ</given-names>
                  </name>
                  <name>
                    <surname>Whitmore</surname>
                    <given-names>AV</given-names>
                  </name>
                  <name>
                    <surname>Zimmer</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Young</surname>
                    <given-names>MP</given-names>
                  </name>
                  <name>
                    <surname>Jenkins</surname>
                    <given-names>JL</given-names>
                  </name>
                  <name>
                    <surname>Glick</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Glen</surname>
                    <given-names>RC</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">From in silico target prediction to multi-target drug design: current databases, methods and applications</article-title>
                <source>J Proteom</source>
                <year>2011</year>
                <volume>74</volume>
                <issue>12</issue>
                <fpage>2554</fpage>
                <lpage>2574</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXhsVOjtrfE</pub-id>
                <pub-id pub-id-type="doi">10.1016/j.jprot.2011.05.011</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR18">
              <label>18.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>van Westen</surname>
                    <given-names>GJ</given-names>
                  </name>
                  <name>
                    <surname>Wegner</surname>
                    <given-names>JK</given-names>
                  </name>
                  <name>
                    <surname>IJzerman</surname>
                    <given-names>AP</given-names>
                  </name>
                  <name>
                    <surname>van Vlijmen</surname>
                    <given-names>HW</given-names>
                  </name>
                  <name>
                    <surname>Bender</surname>
                    <given-names>A</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Proteochemometric modeling as a tool to design selective compounds and for extrapolating to novel targets</article-title>
                <source>MedChemComm</source>
                <year>2011</year>
                <volume>2</volume>
                <issue>1</issue>
                <fpage>16</fpage>
                <lpage>30</lpage>
                <pub-id pub-id-type="doi">10.1039/C0MD00165A</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR19">
              <label>19.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Westen</surname>
                    <given-names>G</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Benchmarking of protein descriptor sets in proteochemometric modeling (part 1): comparative study of 13 amino acid descriptor sets</article-title>
                <source>J Cheminform</source>
                <year>2013</year>
                <volume>5</volume>
                <fpage>41</fpage>
                <pub-id pub-id-type="pmid">24059694</pub-id>
                <pub-id pub-id-type="pmcid">3848949</pub-id>
                <pub-id pub-id-type="doi">10.1186/1758-2946-5-41</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXhsFOrtrnI</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR20">
              <label>20.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Cortés-Ciriano</surname>
                    <given-names>I</given-names>
                  </name>
                  <name>
                    <surname>Ain</surname>
                    <given-names>QU</given-names>
                  </name>
                  <name>
                    <surname>Subramanian</surname>
                    <given-names>V</given-names>
                  </name>
                  <name>
                    <surname>Lenselink</surname>
                    <given-names>EB</given-names>
                  </name>
                  <name>
                    <surname>Méndez-Lucio</surname>
                    <given-names>O</given-names>
                  </name>
                  <name>
                    <surname>IJzerman</surname>
                    <given-names>AP</given-names>
                  </name>
                  <name>
                    <surname>Wohlfahrt</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>Prusis</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>Malliavin</surname>
                    <given-names>TE</given-names>
                  </name>
                  <name>
                    <surname>van Westen</surname>
                    <given-names>GJ</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Polypharmacology modelling using proteochemometrics (PCM): recent methodological developments, applications to target families, and future prospects</article-title>
                <source>MedChemComm</source>
                <year>2015</year>
                <volume>6</volume>
                <issue>1</issue>
                <fpage>24</fpage>
                <lpage>50</lpage>
                <pub-id pub-id-type="doi">10.1039/C4MD00216D</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXhslagsLrE</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR21">
              <label>21.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Qiu</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Qiu</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Feng</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Wu</surname>
                    <given-names>D</given-names>
                  </name>
                  <name>
                    <surname>Yang</surname>
                    <given-names>Y</given-names>
                  </name>
                  <name>
                    <surname>Tang</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Cao</surname>
                    <given-names>Z</given-names>
                  </name>
                  <name>
                    <surname>Zhu</surname>
                    <given-names>R</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">The recent progress in proteochemometric modelling: focusing on target descriptors, cross-term descriptors and application scope</article-title>
                <source>Brief Bioinform</source>
                <year>2016</year>
                <volume>18</volume>
                <issue>1</issue>
                <fpage>125</fpage>
                <lpage>136</lpage>
                <pub-id pub-id-type="pmid">26873661</pub-id>
                <pub-id pub-id-type="doi">10.1093/bib/bbw004</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXltlGjtL8%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR22">
              <label>22.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Morris</surname>
                    <given-names>GM</given-names>
                  </name>
                  <name>
                    <surname>Goodsell</surname>
                    <given-names>DS</given-names>
                  </name>
                  <name>
                    <surname>Halliday</surname>
                    <given-names>RS</given-names>
                  </name>
                  <name>
                    <surname>Huey</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Hart</surname>
                    <given-names>WE</given-names>
                  </name>
                  <name>
                    <surname>Belew</surname>
                    <given-names>RK</given-names>
                  </name>
                  <name>
                    <surname>Olson</surname>
                    <given-names>AJ</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Automated docking using a Lamarckian genetic algorithm and an empirical binding free energy function</article-title>
                <source>J Comput Chem</source>
                <year>1998</year>
                <volume>19</volume>
                <issue>14</issue>
                <fpage>1639</fpage>
                <lpage>1662</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaK1cXntFemur4%3D</pub-id>
                <pub-id pub-id-type="doi">10.1002/(SICI)1096-987X(19981115)19:14&lt;1639::AID-JCC10>3.0.CO;2-B</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR23">
              <label>23.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Friesner</surname>
                    <given-names>RA</given-names>
                  </name>
                  <name>
                    <surname>Banks</surname>
                    <given-names>JL</given-names>
                  </name>
                  <name>
                    <surname>Murphy</surname>
                    <given-names>RB</given-names>
                  </name>
                  <name>
                    <surname>Halgren</surname>
                    <given-names>TA</given-names>
                  </name>
                  <name>
                    <surname>Klicic</surname>
                    <given-names>JJ</given-names>
                  </name>
                  <name>
                    <surname>Mainz</surname>
                    <given-names>DT</given-names>
                  </name>
                  <name>
                    <surname>Repasky</surname>
                    <given-names>MP</given-names>
                  </name>
                  <name>
                    <surname>Knoll</surname>
                    <given-names>EH</given-names>
                  </name>
                  <name>
                    <surname>Shelley</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Perry</surname>
                    <given-names>JK</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Glide: a new approach for rapid, accurate docking and scoring. 1. Method and assessment of docking accuracy</article-title>
                <source>J Med Chem</source>
                <year>2004</year>
                <volume>47</volume>
                <issue>7</issue>
                <fpage>1739</fpage>
                <lpage>1749</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2cXhsFyit74%3D</pub-id>
                <pub-id pub-id-type="pmid">15027865</pub-id>
                <pub-id pub-id-type="doi">10.1021/jm0306430</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR24">
              <label>24.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>McGann</surname>
                    <given-names>M</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Fred pose prediction and virtual screening accuracy</article-title>
                <source>J Chem Inf Model</source>
                <year>2011</year>
                <volume>51</volume>
                <issue>3</issue>
                <fpage>578</fpage>
                <lpage>596</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXhvFGqsbk%3D</pub-id>
                <pub-id pub-id-type="pmid">21323318</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci100436p</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR25">
              <label>25.</label>
              <mixed-citation publication-type="other">Wallach I, Dzamba M, Heifets A (2015) Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1510.02855" ext-link-type="uri">arXiv:1510.02855</ext-link></mixed-citation>
            </ref>
            <ref id="CR26">
              <label>26.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Bender</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Glen</surname>
                    <given-names>RC</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Molecular similarity: a key technique in molecular informatics</article-title>
                <source>Org Biomol Chem</source>
                <year>2004</year>
                <volume>2</volume>
                <issue>22</issue>
                <fpage>3204</fpage>
                <lpage>3218</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2cXpsVOqt74%3D</pub-id>
                <pub-id pub-id-type="pmid">15534697</pub-id>
                <pub-id pub-id-type="doi">10.1039/b409813g</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR27">
              <label>27.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Nigsch</surname>
                    <given-names>F</given-names>
                  </name>
                  <name>
                    <surname>Bender</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Jenkins</surname>
                    <given-names>JL</given-names>
                  </name>
                  <name>
                    <surname>Mitchell</surname>
                    <given-names>JB</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Ligand-target prediction using winnow and naive Bayesian algorithms and the implications of overall performance statistics</article-title>
                <source>J Chem Inf Model</source>
                <year>2008</year>
                <volume>48</volume>
                <issue>12</issue>
                <fpage>2313</fpage>
                <lpage>2325</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXhsVKmt7fN</pub-id>
                <pub-id pub-id-type="pmid">19055411</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci800079x</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR28">
              <label>28.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Lowe</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Mussa</surname>
                    <given-names>HY</given-names>
                  </name>
                  <name>
                    <surname>Nigsch</surname>
                    <given-names>F</given-names>
                  </name>
                  <name>
                    <surname>Glen</surname>
                    <given-names>RC</given-names>
                  </name>
                  <name>
                    <surname>Mitchell</surname>
                    <given-names>JB</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Predicting the mechanism of phospholipidosis</article-title>
                <source>J Cheminform</source>
                <year>2012</year>
                <volume>4</volume>
                <issue>1</issue>
                <fpage>2</fpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XksFGmtLo%3D</pub-id>
                <pub-id pub-id-type="pmid">22281160</pub-id>
                <pub-id pub-id-type="pmcid">3398306</pub-id>
                <pub-id pub-id-type="doi">10.1186/1758-2946-4-2</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR29">
              <label>29.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Svetnik</surname>
                    <given-names>V</given-names>
                  </name>
                  <name>
                    <surname>Liaw</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Tong</surname>
                    <given-names>C</given-names>
                  </name>
                  <name>
                    <surname>Culberson</surname>
                    <given-names>JC</given-names>
                  </name>
                  <name>
                    <surname>Sheridan</surname>
                    <given-names>RP</given-names>
                  </name>
                  <name>
                    <surname>Feuston</surname>
                    <given-names>BP</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Random forest: a classification and regression tool for compound classification and QSAR modeling</article-title>
                <source>J Chem Inf Comput Sci</source>
                <year>2003</year>
                <volume>43</volume>
                <issue>6</issue>
                <fpage>1947</fpage>
                <lpage>1958</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD3sXos1Wiu7s%3D</pub-id>
                <pub-id pub-id-type="pmid">14632445</pub-id>
                <pub-id pub-id-type="pmcid">14632445</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci034160g</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR30">
              <label>30.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Lowe</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Mussa</surname>
                    <given-names>HY</given-names>
                  </name>
                  <name>
                    <surname>Mitchell</surname>
                    <given-names>JB</given-names>
                  </name>
                  <name>
                    <surname>Glen</surname>
                    <given-names>RC</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Classifying molecules using a sparse probabilistic kernel binary classifier</article-title>
                <source>J Chem Inf Model</source>
                <year>2011</year>
                <volume>51</volume>
                <issue>7</issue>
                <fpage>1539</fpage>
                <lpage>1544</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXos1Whtbk%3D</pub-id>
                <pub-id pub-id-type="pmid">21696153</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci200128w</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR31">
              <label>31.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Ma</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Sheridan</surname>
                    <given-names>RP</given-names>
                  </name>
                  <name>
                    <surname>Liaw</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Dahl</surname>
                    <given-names>GE</given-names>
                  </name>
                  <name>
                    <surname>Svetnik</surname>
                    <given-names>V</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Deep neural nets as a method for quantitative structure–activity relationships</article-title>
                <source>J Chem Inf Model</source>
                <year>2015</year>
                <volume>55</volume>
                <issue>2</issue>
                <fpage>263</fpage>
                <lpage>274</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhvFGns70%3D</pub-id>
                <pub-id pub-id-type="pmid">25635324</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci500747n</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR32">
              <label>32.</label>
              <mixed-citation publication-type="other">Dahl GE, Jaitly N, Salakhutdinov R (2014) Multi-task neural networks for QSAR predictions. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1406.1231" ext-link-type="uri">arXiv:1406.1231</ext-link></mixed-citation>
            </ref>
            <ref id="CR33">
              <label>33.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Ramsundar</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Liu</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Wu</surname>
                    <given-names>Z</given-names>
                  </name>
                  <name>
                    <surname>Verras</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Tudor</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Sheridan</surname>
                    <given-names>RP</given-names>
                  </name>
                  <name>
                    <surname>Pande</surname>
                    <given-names>V</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Is multitask deep learning practical for pharma?</article-title>
                <source>J Chem Inf Model</source>
                <year>2017</year>
                <volume>57</volume>
                <issue>8</issue>
                <fpage>2068</fpage>
                <lpage>2076</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXhtFCisr7O</pub-id>
                <pub-id pub-id-type="pmid">28692267</pub-id>
                <pub-id pub-id-type="doi">10.1021/acs.jcim.7b00146</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR34">
              <label>34.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Iwata</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Sawada</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Mizutani</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Kotera</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Yamanishi</surname>
                    <given-names>Y</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Large-scale prediction of beneficial drug combinations using drug efficacy and target profiles</article-title>
                <source>J Chem Inf Model</source>
                <year>2015</year>
                <volume>55</volume>
                <issue>12</issue>
                <fpage>2705</fpage>
                <lpage>2716</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhvFamtL7O</pub-id>
                <pub-id pub-id-type="pmid">26624799</pub-id>
                <pub-id pub-id-type="doi">10.1021/acs.jcim.5b00444</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR35">
              <label>35.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Li</surname>
                    <given-names>Z</given-names>
                  </name>
                  <name>
                    <surname>Han</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>You</surname>
                    <given-names>Z-H</given-names>
                  </name>
                  <name>
                    <surname>Li</surname>
                    <given-names>X</given-names>
                  </name>
                  <name>
                    <surname>Zhang</surname>
                    <given-names>Y</given-names>
                  </name>
                  <name>
                    <surname>Yu</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Nie</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Chen</surname>
                    <given-names>X</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">In silico prediction of drug–target interaction networks based on drug chemical structure and protein sequences</article-title>
                <source>Sci Rep</source>
                <year>2017</year>
                <volume>7</volume>
                <issue>1</issue>
                <fpage>11174</fpage>
                <pub-id pub-id-type="pmid">28894115</pub-id>
                <pub-id pub-id-type="pmcid">5593914</pub-id>
                <pub-id pub-id-type="doi">10.1038/s41598-017-10724-0</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtlOnsbzM</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR36">
              <label>36.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Yabuuchi</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Niijima</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Takematsu</surname>
                    <given-names>H</given-names>
                  </name>
                  <name>
                    <surname>Ida</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Hirokawa</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Hara</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Ogawa</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Minowa</surname>
                    <given-names>Y</given-names>
                  </name>
                  <name>
                    <surname>Tsujimoto</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>Okuno</surname>
                    <given-names>Y</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Analysis of multiple compound–protein interactions reveals novel bioactive molecules</article-title>
                <source>Mol Syst Biol</source>
                <year>2011</year>
                <volume>7</volume>
                <issue>1</issue>
                <fpage>472</fpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXltFShsbY%3D</pub-id>
                <pub-id pub-id-type="pmid">21364574</pub-id>
                <pub-id pub-id-type="pmcid">3094066</pub-id>
                <pub-id pub-id-type="doi">10.1038/msb.2011.5</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR37">
              <label>37.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Lapinsh</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Prusis</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>Lundstedt</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Wikberg</surname>
                    <given-names>JE</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Proteochemometrics modeling of the interaction of amine g-protein coupled receptors with a diverse set of ligands</article-title>
                <source>Mol Pharmacol</source>
                <year>2002</year>
                <volume>61</volume>
                <issue>6</issue>
                <fpage>1465</fpage>
                <lpage>1475</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD38XksVWrtb4%3D</pub-id>
                <pub-id pub-id-type="pmid">12021408</pub-id>
                <pub-id pub-id-type="doi">10.1124/mol.61.6.1465</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR38">
              <label>38.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Lenselink</surname>
                    <given-names>EB</given-names>
                  </name>
                  <name>
                    <surname>Ten Dijke</surname>
                    <given-names>N</given-names>
                  </name>
                  <name>
                    <surname>Bongers</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Papadatos</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>van Vlijmen</surname>
                    <given-names>HW</given-names>
                  </name>
                  <name>
                    <surname>Kowalczyk</surname>
                    <given-names>W</given-names>
                  </name>
                  <name>
                    <surname>IJzerman</surname>
                    <given-names>AP</given-names>
                  </name>
                  <name>
                    <surname>van Westen</surname>
                    <given-names>GJ</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Beyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set</article-title>
                <source>J Cheminform</source>
                <year>2017</year>
                <volume>9</volume>
                <issue>1</issue>
                <fpage>45</fpage>
                <pub-id pub-id-type="pmid">29086168</pub-id>
                <pub-id pub-id-type="pmcid">5555960</pub-id>
                <pub-id pub-id-type="doi">10.1186/s13321-017-0232-0</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXnsVygtLk%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR39">
              <label>39.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Koutsoukas</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Monaghan</surname>
                    <given-names>KJ</given-names>
                  </name>
                  <name>
                    <surname>Li</surname>
                    <given-names>X</given-names>
                  </name>
                  <name>
                    <surname>Huan</surname>
                    <given-names>J</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data</article-title>
                <source>J Cheminform</source>
                <year>2017</year>
                <volume>9</volume>
                <issue>1</issue>
                <fpage>42</fpage>
                <pub-id pub-id-type="pmid">29086090</pub-id>
                <pub-id pub-id-type="pmcid">5489441</pub-id>
                <pub-id pub-id-type="doi">10.1186/s13321-017-0226-y</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR40">
              <label>40.</label>
              <mixed-citation publication-type="other">Wang C, Liu J, Luo F, Tan Y, Deng Z, Hu Q-N (2014) Pairwise input neural network for target–ligand interaction prediction. In: 2014 IEEE international conference on bioinformatics and biomedicine (BIBM). IEEE, pp 67–70</mixed-citation>
            </ref>
            <ref id="CR41">
              <label>41.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Papadatos</surname>
                    <given-names>G</given-names>
                  </name>
                  <name>
                    <surname>Gaulton</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Hersey</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Overington</surname>
                    <given-names>JP</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Activity, assay and target data curation and quality in the ChEMBL database</article-title>
                <source>J Comput Aided Mol Des</source>
                <year>2015</year>
                <volume>29</volume>
                <issue>9</issue>
                <fpage>885</fpage>
                <lpage>896</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXht1aks73N</pub-id>
                <pub-id pub-id-type="pmid">26201396</pub-id>
                <pub-id pub-id-type="pmcid">4607714</pub-id>
                <pub-id pub-id-type="doi">10.1007/s10822-015-9860-5</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR42">
              <label>42.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Jaeger</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Fulle</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Turk</surname>
                    <given-names>S</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Mol2vec: unsupervised machine learning approach with chemical intuition</article-title>
                <source>J Chem Inf Model</source>
                <year>2018</year>
                <volume>58</volume>
                <issue>1</issue>
                <fpage>27</fpage>
                <lpage>35</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXitVWgurjN</pub-id>
                <pub-id pub-id-type="pmid">29268609</pub-id>
                <pub-id pub-id-type="doi">10.1021/acs.jcim.7b00616</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR43">
              <label>43.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Asgari</surname>
                    <given-names>E</given-names>
                  </name>
                  <name>
                    <surname>Mofrad</surname>
                    <given-names>MR</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>
                <source>PLoS ONE</source>
                <year>2015</year>
                <volume>10</volume>
                <issue>11</issue>
                <fpage>0141287</fpage>
                <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhvFyisbjJ</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR44">
              <label>44.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Irwin</surname>
                    <given-names>JJ</given-names>
                  </name>
                  <name>
                    <surname>Sterling</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Mysinger</surname>
                    <given-names>MM</given-names>
                  </name>
                  <name>
                    <surname>Bolstad</surname>
                    <given-names>ES</given-names>
                  </name>
                  <name>
                    <surname>Coleman</surname>
                    <given-names>RG</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Zinc: a free tool to discover chemistry for biology</article-title>
                <source>J Chem Inf Model</source>
                <year>2012</year>
                <volume>52</volume>
                <issue>7</issue>
                <fpage>1757</fpage>
                <lpage>1768</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XmvFGnsrg%3D</pub-id>
                <pub-id pub-id-type="pmid">22587354</pub-id>
                <pub-id pub-id-type="pmcid">3402020</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci3001277</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR45">
              <label>45.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Consortium</surname>
                    <given-names>U</given-names>
                  </name>
                  <etal />
                </person-group>
                <article-title xml:lang="en">Uniprot: the universal protein knowledgebase</article-title>
                <source>Nucleic Acids Res</source>
                <year>2018</year>
                <volume>46</volume>
                <issue>5</issue>
                <fpage>2699</fpage>
                <pub-id pub-id-type="doi">10.1093/nar/gky092</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitlGjtLnK</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR46">
              <label>46.</label>
              <mixed-citation publication-type="other">Program NT (2014) Tox21 challenge. <ext-link xlink:href="https://tripod.nih.gov/tox21/challenge/" ext-link-type="uri">https://tripod.nih.gov/tox21/challenge/</ext-link>. Accessed 3 Dec 2018</mixed-citation>
            </ref>
            <ref id="CR47">
              <label>47.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Sparck Jones</surname>
                    <given-names>K</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">A statistical interpretation of term specificity and its application in retrieval</article-title>
                <source>J Doc</source>
                <year>1972</year>
                <volume>28</volume>
                <issue>1</issue>
                <fpage>11</fpage>
                <lpage>21</lpage>
                <pub-id pub-id-type="doi">10.1108/eb026526</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR48">
              <label>48.</label>
              <mixed-citation publication-type="other">Ribeiro LF, Saverese PH, Figueiredo DR (2017) Struc2vec: learning node representations from structural identity. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, pp 385–394</mixed-citation>
            </ref>
            <ref id="CR49">
              <label>49.</label>
              <mixed-citation publication-type="other">Dong Y, Chawla NV, Swami A (2017) Metapath2vec: scalable representation learning for heterogeneous networks. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, pp 135–144</mixed-citation>
            </ref>
            <ref id="CR50">
              <label>50.</label>
              <mixed-citation publication-type="other">Grover A, Leskovec J (2016) Node2vec: scalable feature learning for networks. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, pp 855–864</mixed-citation>
            </ref>
            <ref id="CR51">
              <label>51.</label>
              <mixed-citation publication-type="other">Saxe AM, Bansal Y, Dapello J, Advani M, Kolchinsky A,Tracey BD, Cox DD(2018) On the information bottleneck theory of deeplearning. In: 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. <ext-link xlink:href="https://openreview.net/forum?id=ry_WPG-A-" ext-link-type="uri">https://openreview.net/forum?id=ry_WPG-A-</ext-link></mixed-citation>
            </ref>
            <ref id="CR52">
              <label>52.</label>
              <mixed-citation publication-type="book">
                <person-group person-group-type="author">
                  <name>
                    <surname>Ramsundar</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Eastman</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>Leswing</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Walters</surname>
                    <given-names>P</given-names>
                  </name>
                  <name>
                    <surname>Pande</surname>
                    <given-names>V</given-names>
                  </name>
                </person-group>
                <source>Deep learning for the life sciences</source>
                <year>2019</year>
                <publisher-loc>Sebastopol</publisher-loc>
                <publisher-name>O’Reilly Media</publisher-name>
              </mixed-citation>
            </ref>
            <ref id="CR53">
              <label>53.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Wu</surname>
                    <given-names>Z</given-names>
                  </name>
                  <name>
                    <surname>Ramsundar</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Feinberg</surname>
                    <given-names>EN</given-names>
                  </name>
                  <name>
                    <surname>Gomes</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Geniesse</surname>
                    <given-names>C</given-names>
                  </name>
                  <name>
                    <surname>Pappu</surname>
                    <given-names>AS</given-names>
                  </name>
                  <name>
                    <surname>Leswing</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Pande</surname>
                    <given-names>V</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Moleculenet: a benchmark for molecular machine learning</article-title>
                <source>Chem Sci</source>
                <year>2018</year>
                <volume>9</volume>
                <issue>2</issue>
                <fpage>513</fpage>
                <lpage>530</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXhslChtrbO</pub-id>
                <pub-id pub-id-type="pmid">29629118</pub-id>
                <pub-id pub-id-type="pmcid">29629118</pub-id>
                <pub-id pub-id-type="doi">10.1039/C7SC02664A</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR54">
              <label>54.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Saito</surname>
                    <given-names>T</given-names>
                  </name>
                  <name>
                    <surname>Rehmsmeier</surname>
                    <given-names>M</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">The precision–recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets</article-title>
                <source>PLoS ONE</source>
                <year>2015</year>
                <volume>10</volume>
                <issue>3</issue>
                <fpage>0118432</fpage>
                <pub-id pub-id-type="doi">10.1371/journal.pone.0118432</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhslSjurbF</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR55">
              <label>55.</label>
              <mixed-citation publication-type="book">
                <person-group person-group-type="author">
                  <name>
                    <surname>Olivas</surname>
                    <given-names>ES</given-names>
                  </name>
                </person-group>
                <source>Handbook of research on machine learning applications and trends</source>
                <year>2009</year>
                <publisher-loc>Hershey</publisher-loc>
                <publisher-name>IGI Global</publisher-name>
              </mixed-citation>
            </ref>
            <ref id="CR56">
              <label>56.</label>
              <mixed-citation publication-type="book">
                <person-group person-group-type="author">
                  <name>
                    <surname>Goodfellow</surname>
                    <given-names>I</given-names>
                  </name>
                  <name>
                    <surname>Bengio</surname>
                    <given-names>Y</given-names>
                  </name>
                  <name>
                    <surname>Courville</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Bengio</surname>
                    <given-names>Y</given-names>
                  </name>
                </person-group>
                <source>Deep learning</source>
                <year>2016</year>
                <publisher-loc>Cambridge</publisher-loc>
                <publisher-name>MIT Press</publisher-name>
              </mixed-citation>
            </ref>
            <ref id="CR57">
              <label>57.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Bender</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Jenkins</surname>
                    <given-names>JL</given-names>
                  </name>
                  <name>
                    <surname>Scheiber</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Sukuru</surname>
                    <given-names>SCK</given-names>
                  </name>
                  <name>
                    <surname>Glick</surname>
                    <given-names>M</given-names>
                  </name>
                  <name>
                    <surname>Davies</surname>
                    <given-names>JW</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">How similar are similarity searching methods? A principal component analysis of molecular descriptor space</article-title>
                <source>J Chem Inf Model</source>
                <year>2009</year>
                <volume>49</volume>
                <issue>1</issue>
                <fpage>108</fpage>
                <lpage>119</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1MXisVahtQ%3D%3D</pub-id>
                <pub-id pub-id-type="pmid">19123924</pub-id>
                <pub-id pub-id-type="doi">10.1021/ci800249s</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR58">
              <label>58.</label>
              <mixed-citation publication-type="other">RDKit: open-source cheminformatics. <ext-link xlink:href="http://www.rdkit.org" ext-link-type="uri">http://www.rdkit.org</ext-link>. Accessed 11 Apr 2018</mixed-citation>
            </ref>
            <ref id="CR59">
              <label>59.</label>
              <mixed-citation publication-type="other">Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J (2013) Distributed representations of words and phrases and their compositionality. In: Advances in neural information processing systems, pp 3111–3119</mixed-citation>
            </ref>
            <ref id="CR60">
              <label>60.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Gómez-Bombarelli</surname>
                    <given-names>R</given-names>
                  </name>
                  <name>
                    <surname>Wei</surname>
                    <given-names>JN</given-names>
                  </name>
                  <name>
                    <surname>Duvenaud</surname>
                    <given-names>D</given-names>
                  </name>
                  <name>
                    <surname>Hernández-Lobato</surname>
                    <given-names>JM</given-names>
                  </name>
                  <name>
                    <surname>Sánchez-Lengeling</surname>
                    <given-names>B</given-names>
                  </name>
                  <name>
                    <surname>Sheberla</surname>
                    <given-names>D</given-names>
                  </name>
                  <name>
                    <surname>Aguilera-Iparraguirre</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Hirzel</surname>
                    <given-names>TD</given-names>
                  </name>
                  <name>
                    <surname>Adams</surname>
                    <given-names>RP</given-names>
                  </name>
                  <name>
                    <surname>Aspuru-Guzik</surname>
                    <given-names>A</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Automatic chemical design using a data-driven continuous representation of molecules</article-title>
                <source>ACS Cent Sci</source>
                <year>2018</year>
                <volume>4</volume>
                <issue>2</issue>
                <fpage>268</fpage>
                <lpage>276</lpage>
                <pub-id pub-id-type="pmid">29532027</pub-id>
                <pub-id pub-id-type="pmcid">5833007</pub-id>
                <pub-id pub-id-type="doi">10.1021/acscentsci.7b00572</pub-id>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXntlWquw%3D%3D</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR61">
              <label>61.</label>
              <mixed-citation publication-type="other">Chollet F et al (2015) Keras. <ext-link xlink:href="https://keras.io/" ext-link-type="uri">https://keras.io/</ext-link>. Accessed 27 July 2018</mixed-citation>
            </ref>
            <ref id="CR62">
              <label>62.</label>
              <mixed-citation publication-type="other">Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, Corrado GS, Davis A, Dean J, Devin M, Ghemawat S, Goodfellow I, Harp A, Irving G, Isard M, Jia Y, Jozefowicz R, Kaiser L, Kudlur M, Levenberg J, Mané D, Monga R, Moore S, Murray D, Olah C, Schuster M, Shlens J, Steiner B, Sutskever I, Talwar K, Tucker P, Vanhoucke V, Vasudevan V, Viégas F, Vinyals O, Warden P, Wattenberg M, Wicke M, Yu Y, Zheng X (2015) TensorFlow: large-scale machine learning on heterogeneous systems. Software available from tensorflow.org. <ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>. Accessed 27 July 2018</mixed-citation>
            </ref>
            <ref id="CR63">
              <label>63.</label>
              <mixed-citation publication-type="other">Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1412.6980" ext-link-type="uri">arXiv:1412.6980</ext-link></mixed-citation>
            </ref>
            <ref id="CR64">
              <label>64.</label>
              <mixed-citation publication-type="other">Keskar NS, Mudigere D, Nocedal J, Smelyanskiy M, Tang PTP (2016) On large-batch training for deep learning: generalization gap and sharp minima. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1609.04836" ext-link-type="uri">arXiv:1609.04836</ext-link></mixed-citation>
            </ref>
            <ref id="CR65">
              <label>65.</label>
              <mixed-citation publication-type="book">
                <person-group person-group-type="author">
                  <name>
                    <surname>LeCun</surname>
                    <given-names>Yann A.</given-names>
                  </name>
                  <name>
                    <surname>Bottou</surname>
                    <given-names>Léon</given-names>
                  </name>
                  <name>
                    <surname>Orr</surname>
                    <given-names>Genevieve B.</given-names>
                  </name>
                  <name>
                    <surname>Müller</surname>
                    <given-names>Klaus-Robert</given-names>
                  </name>
                </person-group>
                <article-title>Efficient BackProp</article-title>
                <source>Lecture Notes in Computer Science</source>
                <year>2012</year>
                <publisher-loc>Berlin, Heidelberg</publisher-loc>
                <publisher-name>Springer Berlin Heidelberg</publisher-name>
                <fpage>9</fpage>
                <lpage>48</lpage>
              </mixed-citation>
            </ref>
            <ref id="CR66">
              <label>66.</label>
              <mixed-citation publication-type="other">Xu B, Wang N, Chen T, Li M (2015) Empirical evaluation of rectified activations in convolutional network. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1505.00853" ext-link-type="uri">arXiv:1505.00853</ext-link></mixed-citation>
            </ref>
            <ref id="CR67">
              <label>67.</label>
              <mixed-citation publication-type="other">Clevert D-A, Unterthiner T, Hochreiter S (2015) Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1511.07289" ext-link-type="uri">arXiv:1511.07289</ext-link></mixed-citation>
            </ref>
            <ref id="CR68">
              <label>68.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Hochreiter</surname>
                    <given-names>S</given-names>
                  </name>
                  <name>
                    <surname>Schmidhuber</surname>
                    <given-names>J</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Long short-term memory</article-title>
                <source>Neural Comput</source>
                <year>1997</year>
                <volume>9</volume>
                <issue>8</issue>
                <fpage>1735</fpage>
                <lpage>1780</lpage>
                <pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DyaK1c%2FhvVahsQ%3D%3D</pub-id>
                <pub-id pub-id-type="pmid">9377276</pub-id>
                <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR69">
              <label>69.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Graves</surname>
                    <given-names>A</given-names>
                  </name>
                  <name>
                    <surname>Schmidhuber</surname>
                    <given-names>J</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</article-title>
                <source>Neural Netw</source>
                <year>2005</year>
                <volume>18</volume>
                <issue>5–6</issue>
                <fpage>602</fpage>
                <lpage>610</lpage>
                <pub-id pub-id-type="pmid">16112549</pub-id>
                <pub-id pub-id-type="doi">10.1016/j.neunet.2005.06.042</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR70">
              <label>70.</label>
              <mixed-citation publication-type="journal">
                <person-group person-group-type="author">
                  <name>
                    <surname>Greff</surname>
                    <given-names>K</given-names>
                  </name>
                  <name>
                    <surname>Srivastava</surname>
                    <given-names>RK</given-names>
                  </name>
                  <name>
                    <surname>Koutník</surname>
                    <given-names>J</given-names>
                  </name>
                  <name>
                    <surname>Steunebrink</surname>
                    <given-names>BR</given-names>
                  </name>
                  <name>
                    <surname>Schmidhuber</surname>
                    <given-names>J</given-names>
                  </name>
                </person-group>
                <article-title xml:lang="en">LSTM: a search space odyssey</article-title>
                <source>IEEE Trans Neural Netw Learn Syst</source>
                <year>2017</year>
                <volume>28</volume>
                <issue>10</issue>
                <fpage>2222</fpage>
                <lpage>2232</lpage>
                <pub-id pub-id-type="pmid">27411231</pub-id>
                <pub-id pub-id-type="doi">10.1109/TNNLS.2016.2582924</pub-id>
              </mixed-citation>
            </ref>
            <ref id="CR71">
              <label>71.</label>
              <mixed-citation publication-type="other">Van Den Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, Kalchbrenner N, Senior AW, Kavukcuoglu K (2016) Wavenet: a generative model for raw audio. In: The 9th ISCA Speech Synthesis Workshop, Sunnyvale, CA, USA, 13–15 September 2016, p.125</mixed-citation>
            </ref>
            <ref id="CR72">
              <label>72.</label>
              <mixed-citation publication-type="other">Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z (2016) Rethinking the inception architecture for computer vision. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2818–2826</mixed-citation>
            </ref>
            <ref id="CR73">
              <label>73.</label>
              <mixed-citation publication-type="other">Jozefowicz R, Zaremba W, Sutskever I (2015) An empirical exploration of recurrent network architectures. In: International conference on machine learning, pp 2342–2350</mixed-citation>
            </ref>
          </ref-list>
        </ref-list>
        <app-group>
          <app id="App1">
            <sec id="Sec22">
              <title>Additional file</title>
              <p id="Par85">
                <supplementary-material content-type="local-data" id="MOESM1" xlink:title="Additional file">
                  <media mimetype="application" mime-subtype="msword" xlink:href="MediaObjects/13321_2019_368_MOESM1_ESM.docx" position="anchor">
                    <caption xml:lang="en">
                      <p><ext-link xlink:href="http://doi.org/10.1186/s13321-019-0368-1" ext-link-type="uri">Additional file 1.</ext-link> Supplementary results in the form of 5 Figures and 10 Tables.</p>
                    </caption>
                  </media>
                </supplementary-material>
              </p>
            </sec>
          </app>
        </app-group>
        <glossary>
          <title>Abbreviations</title>
          <def-list>
            <def-item>
              <term>AUC</term>
              <def>
                <p id="Par2">area under the curve</p>
              </def>
            </def-item>
            <def-item>
              <term>CPI</term>
              <def>
                <p id="Par3">compound–protein interaction</p>
              </def>
            </def-item>
            <def-item>
              <term>DNN</term>
              <def>
                <p id="Par4">deep neural network</p>
              </def>
            </def-item>
            <def-item>
              <term>ECFP</term>
              <def>
                <p id="Par5">extended-connectivity fingerprints</p>
              </def>
            </def-item>
            <def-item>
              <term>IB</term>
              <def>
                <p id="Par6">information bottleneck</p>
              </def>
            </def-item>
            <def-item>
              <term>MCC</term>
              <def>
                <p id="Par7">Matthews correlation coeffcient</p>
              </def>
            </def-item>
            <def-item>
              <term>MCPINN</term>
              <def>
                <p id="Par8">multi-channel pairwise input neural networks</p>
              </def>
            </def-item>
            <def-item>
              <term>PCM</term>
              <def>
                <p id="Par9">proteochemometrics</p>
              </def>
            </def-item>
            <def-item>
              <term>PINN</term>
              <def>
                <p id="Par10">pairwise input neural networks</p>
              </def>
            </def-item>
            <def-item>
              <term>PRC</term>
              <def>
                <p id="Par11">precision–recall curve</p>
              </def>
            </def-item>
            <def-item>
              <term>QSAR</term>
              <def>
                <p id="Par12">quantitative structure–activity relationship</p>
              </def>
            </def-item>
            <def-item>
              <term>ROC</term>
              <def>
                <p id="Par13">receiver operator characteristic</p>
              </def>
            </def-item>
            <def-item>
              <term>SCPINN</term>
              <def>
                <p id="Par14">single-channel pairwise input neural networks</p>
              </def>
            </def-item>
            <def-item>
              <term>SMILES</term>
              <def>
                <p id="Par15">simplifed molecular input line entry system</p>
              </def>
            </def-item>
            <def-item>
              <term>TF-IDF</term>
              <def>
                <p id="Par16">term frequency inverse document frequency</p>
              </def>
            </def-item>
          </def-list>
        </glossary>
        <notes notes-type="Misc">
          <title>Publisher's Note</title>
          <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
        </notes>
      </back>
    </article>
